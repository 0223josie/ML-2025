{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Check out the [Tensorflow Playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.80814&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false). Explore the following:\n",
    "\n",
    "   - The patterns learned by a neural net. Try training the default neural network by clicking the Run button (top left). Notice how it quickly finds a good solution for the classification task. The neurons in the first hidden layer have learned simple patterns, while the neurons in the second hidden layer have learned to combine the simple patterns of the first hidden layer into more complex patterns. In general, the more layers there are, the more complex the patterns can be.\n",
    "   \n",
    "   - Activation functions. Try replacing the tanh activation function with a ReLU activation function, and train the network again. Notice that it finds a solution even faster, but this time the boundaries are linear. This is due to the shape of the ReLU function.\n",
    "   - The risk of local minima. Modify the network architecture to have just one hidden layer with three neurons. Train it multiple times (to reset the network weights, click the Reset button next to the Play button). Notice that the training time varies a lot, and sometimes it even gets stuck in a local minimum.\n",
    "   - What happens when neural nets are too small? Remove one neuron to keep just two. Notice that the neural network is now incapable of finding a good solution, even if you try multiple times. The model has too few parameters and systematically underfits the training set.\n",
    "   - What happens when neural nets are large enough? Set the number of neurons to eight, and train the network several times. Notice that it is now consistently fast and never gets stuck. This highlights an important finding in neural network theory: large neural networks rarely get stuck in local minima, and even when they do these local optima are often almost as good as the global optimum. However, they can still get stuck on long plateaus for a long time.\n",
    "   - The risk of vanishing gradients in deep networks. Select the spiral dataset (the bottom-right dataset under “DATA”), and change the network architecture to have four hidden layers with eight neurons each. Notice that training takes much longer and often gets stuck on plateaus for long periods of time. Also notice that the neurons in the highest layers (on the right) tend to evolve faster than the neurons in the lowest layers (on the left). This problem, called the vanishing gradients problem, can be alleviated with better weight initialization and other techniques, better optimizers (such as AdaGrad or Adam), or batch normalization. (discussed in Chapter 11 in the book)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Take a few moments to play with the following code.  Try using the different activation functions (`identity`,`tanh`,`logistic`,`relu`) and solvers (`lbfgs`,`sgd`,`adam`).  Try reconfiguring the size and number of hidden layers.  Try changing the number of classes in your sample data. What do you find? Can you identify a good configuration for 10 classes?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.50740824\n",
      "Iteration 2, loss = 2.24232418\n",
      "Iteration 3, loss = 2.10439910\n",
      "Iteration 4, loss = 1.99862156\n",
      "Iteration 5, loss = 1.89582390\n",
      "Iteration 6, loss = 1.79658236\n",
      "Iteration 7, loss = 1.70515257\n",
      "Iteration 8, loss = 1.61576752\n",
      "Iteration 9, loss = 1.55181395\n",
      "Iteration 10, loss = 1.47151747\n",
      "Iteration 11, loss = 1.39894158\n",
      "Iteration 12, loss = 1.33974524\n",
      "Iteration 13, loss = 1.27806798\n",
      "Iteration 14, loss = 1.22366524\n",
      "Iteration 15, loss = 1.16032015\n",
      "Iteration 16, loss = 1.10268154\n",
      "Iteration 17, loss = 1.04874687\n",
      "Iteration 18, loss = 0.99494592\n",
      "Iteration 19, loss = 0.95577610\n",
      "Iteration 20, loss = 0.90812470\n",
      "Iteration 21, loss = 0.86548117\n",
      "Iteration 22, loss = 0.82138077\n",
      "Iteration 23, loss = 0.76926152\n",
      "Iteration 24, loss = 0.73686544\n",
      "Iteration 25, loss = 0.70781486\n",
      "Iteration 26, loss = 0.66232101\n",
      "Iteration 27, loss = 0.62995076\n",
      "Iteration 28, loss = 0.59282779\n",
      "Iteration 29, loss = 0.55616153\n",
      "Iteration 30, loss = 0.51499904\n",
      "Iteration 31, loss = 0.47811643\n",
      "Iteration 32, loss = 0.44882531\n",
      "Iteration 33, loss = 0.41849433\n",
      "Iteration 34, loss = 0.38913504\n",
      "Iteration 35, loss = 0.36163946\n",
      "Iteration 36, loss = 0.34040324\n",
      "Iteration 37, loss = 0.30594217\n",
      "Iteration 38, loss = 0.28598120\n",
      "Iteration 39, loss = 0.26276429\n",
      "Iteration 40, loss = 0.24345131\n",
      "Iteration 41, loss = 0.22988526\n",
      "Iteration 42, loss = 0.20720296\n",
      "Iteration 43, loss = 0.19148221\n",
      "Iteration 44, loss = 0.18275062\n",
      "Iteration 45, loss = 0.16659085\n",
      "Iteration 46, loss = 0.15596640\n",
      "Iteration 47, loss = 0.14338409\n",
      "Iteration 48, loss = 0.13411522\n",
      "Iteration 49, loss = 0.12726792\n",
      "Iteration 50, loss = 0.11672505\n",
      "Iteration 51, loss = 0.10690785\n",
      "Iteration 52, loss = 0.10138948\n",
      "Iteration 53, loss = 0.09541864\n",
      "Iteration 54, loss = 0.08940161\n",
      "Iteration 55, loss = 0.08371075\n",
      "Iteration 56, loss = 0.07929981\n",
      "Iteration 57, loss = 0.07510001\n",
      "Iteration 58, loss = 0.07087210\n",
      "Iteration 59, loss = 0.06589635\n",
      "Iteration 60, loss = 0.06280775\n",
      "Iteration 61, loss = 0.06038441\n",
      "Iteration 62, loss = 0.05681139\n",
      "Iteration 63, loss = 0.05503107\n",
      "Iteration 64, loss = 0.05196756\n",
      "Iteration 65, loss = 0.04968749\n",
      "Iteration 66, loss = 0.04759642\n",
      "Iteration 67, loss = 0.04584385\n",
      "Iteration 68, loss = 0.04393714\n",
      "Iteration 69, loss = 0.04191526\n",
      "Iteration 70, loss = 0.04105333\n",
      "Iteration 71, loss = 0.03967540\n",
      "Iteration 72, loss = 0.03740827\n",
      "Iteration 73, loss = 0.03621029\n",
      "Iteration 74, loss = 0.03501294\n",
      "Iteration 75, loss = 0.03372596\n",
      "Iteration 76, loss = 0.03279462\n",
      "Iteration 77, loss = 0.03155252\n",
      "Iteration 78, loss = 0.03062440\n",
      "Iteration 79, loss = 0.02968990\n",
      "Iteration 80, loss = 0.02876813\n",
      "Iteration 81, loss = 0.02773665\n",
      "Iteration 82, loss = 0.02719263\n",
      "Iteration 83, loss = 0.02638956\n",
      "Iteration 84, loss = 0.02559538\n",
      "Iteration 85, loss = 0.02495930\n",
      "Iteration 86, loss = 0.02451315\n",
      "Iteration 87, loss = 0.02358306\n",
      "Iteration 88, loss = 0.02303319\n",
      "Iteration 89, loss = 0.02234476\n",
      "Iteration 90, loss = 0.02175549\n",
      "Iteration 91, loss = 0.02125596\n",
      "Iteration 92, loss = 0.02077529\n",
      "Iteration 93, loss = 0.02026287\n",
      "Iteration 94, loss = 0.01982523\n",
      "Iteration 95, loss = 0.01921924\n",
      "Iteration 96, loss = 0.01880497\n",
      "Iteration 97, loss = 0.01842403\n",
      "Iteration 98, loss = 0.01805180\n",
      "Iteration 99, loss = 0.01750538\n",
      "Iteration 100, loss = 0.01719427\n",
      "Iteration 101, loss = 0.01678749\n",
      "Iteration 102, loss = 0.01662444\n",
      "Iteration 103, loss = 0.01604795\n",
      "Iteration 104, loss = 0.01575271\n",
      "Iteration 105, loss = 0.01540340\n",
      "Iteration 106, loss = 0.01503608\n",
      "Iteration 107, loss = 0.01481471\n",
      "Iteration 108, loss = 0.01441864\n",
      "Iteration 109, loss = 0.01414567\n",
      "Iteration 110, loss = 0.01388037\n",
      "Iteration 111, loss = 0.01359000\n",
      "Iteration 112, loss = 0.01330263\n",
      "Iteration 113, loss = 0.01314192\n",
      "Iteration 114, loss = 0.01282532\n",
      "Iteration 115, loss = 0.01256657\n",
      "Iteration 116, loss = 0.01237562\n",
      "Iteration 117, loss = 0.01212034\n",
      "Iteration 118, loss = 0.01189238\n",
      "Iteration 119, loss = 0.01167773\n",
      "Iteration 120, loss = 0.01147924\n",
      "Iteration 121, loss = 0.01128115\n",
      "Iteration 122, loss = 0.01111677\n",
      "Iteration 123, loss = 0.01093448\n",
      "Iteration 124, loss = 0.01071610\n",
      "Iteration 125, loss = 0.01054775\n",
      "Iteration 126, loss = 0.01037178\n",
      "Iteration 127, loss = 0.01019289\n",
      "Iteration 128, loss = 0.01004417\n",
      "Iteration 129, loss = 0.00990945\n",
      "Iteration 130, loss = 0.00973618\n",
      "Iteration 131, loss = 0.00957907\n",
      "Iteration 132, loss = 0.00941424\n",
      "Iteration 133, loss = 0.00928213\n",
      "Iteration 134, loss = 0.00914266\n",
      "Iteration 135, loss = 0.00900627\n",
      "Iteration 136, loss = 0.00886333\n",
      "Iteration 137, loss = 0.00874054\n",
      "Iteration 138, loss = 0.00862395\n",
      "Iteration 139, loss = 0.00853744\n",
      "Iteration 140, loss = 0.00838802\n",
      "Iteration 141, loss = 0.00825504\n",
      "Iteration 142, loss = 0.00815234\n",
      "Iteration 143, loss = 0.00804165\n",
      "Iteration 144, loss = 0.00791523\n",
      "Iteration 145, loss = 0.00782825\n",
      "Iteration 146, loss = 0.00767821\n",
      "Iteration 147, loss = 0.00759997\n",
      "Iteration 148, loss = 0.00748213\n",
      "Iteration 149, loss = 0.00738882\n",
      "Iteration 150, loss = 0.00728363\n",
      "Iteration 151, loss = 0.00719147\n",
      "Iteration 152, loss = 0.00708988\n",
      "Iteration 153, loss = 0.00698497\n",
      "Iteration 154, loss = 0.00686294\n",
      "Iteration 155, loss = 0.00677560\n",
      "Iteration 156, loss = 0.00669293\n",
      "Iteration 157, loss = 0.00658949\n",
      "Iteration 158, loss = 0.00652429\n",
      "Iteration 159, loss = 0.00644914\n",
      "Iteration 160, loss = 0.00635794\n",
      "Iteration 161, loss = 0.00628020\n",
      "Iteration 162, loss = 0.00621173\n",
      "Iteration 163, loss = 0.00611986\n",
      "Iteration 164, loss = 0.00605868\n",
      "Iteration 165, loss = 0.00597608\n",
      "Iteration 166, loss = 0.00591459\n",
      "Iteration 167, loss = 0.00584417\n",
      "Iteration 168, loss = 0.00577430\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 0.48\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate a dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_classes=10, random_state=1)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=1)\n",
    "\n",
    "# Initialize the MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(75,20), max_iter=1000, alpha=1e-4,\n",
    "                    solver='sgd', activation=\"relu\", verbose=10, random_state=1,\n",
    "                    learning_rate_init=.05)\n",
    "\n",
    "# Train the MLP\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic: Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
    "Accuracy: 0.45\n",
    "identity: Accuracy: 0.28\n",
    "tanh: Accuracy: 0.41\n",
    "relu: Accuracy: 0.48\n",
    "best: \n",
    "not true: the bigger the network is, the better the accuracy is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 \n",
    "\n",
    "Try building a MLP in Keras to fit the MNIST handwriting data using the Sequential API. Here are some tips:\n",
    "\n",
    "- Make sure to flatten your images with a \"Flatten\" layer\n",
    "- Add one or two Dense layers with ReLU activation\n",
    "- Finish with a dense output layer with 10 neurons (one for each digit)\n",
    "- Compile the model with the `adam` optimizer, `sparse_categorical_crossentropy` loss, and `accuracy` metric\n",
    "- Use a validation_split parameter with 20 percent of your data for validation during training\n",
    "- Train with a reasonable number of epochs (e.g. 5-10) and evaluate your performance on the test set\n",
    "- Explore with different numbers of neurons, layers, and epochs!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (4.14.1)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-2.0.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (2.3.1)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.9)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in /home/codespace/.local/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading wrapt-2.0.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (121 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (408 kB)\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt_einsum, ml_dtypes, mdurl, markdown, h5py, grpcio, google_pasta, gast, absl-py, tensorboard, markdown-it-py, astunparse, rich, keras, tensorflow\n",
      "\u001b[2K   \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/25\u001b[0m [libclang]\u001b[33m  WARNING: The script wheel is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/25\u001b[0m [markdown]m]-data-server]\u001b[33m  WARNING: The script markdown_py is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m19/25\u001b[0m [tensorboard]]\u001b[33m  WARNING: The script tensorboard is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m20/25\u001b[0m [markdown-it-py]\u001b[33m  WARNING: The script markdown-it is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m24/25\u001b[0m [tensorflow]\u001b[33m  WARNING: The scripts import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert and toco are installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/25\u001b[0m [tensorflow]5\u001b[0m [tensorflow]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.9.23 gast-0.6.0 google_pasta-0.2.0 grpcio-1.76.0 h5py-3.15.1 keras-3.12.0 libclang-18.1.1 markdown-3.10 markdown-it-py-4.0.0 mdurl-0.1.2 ml_dtypes-0.5.3 namex-0.1.0 opt_einsum-3.4.0 optree-0.17.0 protobuf-6.33.0 rich-14.2.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.2.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-2.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 16:33:44.464202: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-05 16:33:45.406559: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-05 16:33:47.705499: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Training data shape: (60000, 28, 28)\n",
      "Training labels shape: (60000,)\n",
      "Test data shape: (10000, 28, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2025-11-05 16:33:52.068851: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the model...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 16:33:52.427242: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 150528000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m374/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7676 - loss: 0.7708"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 16:33:54.572744: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 37632000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8725 - loss: 0.4343 - val_accuracy: 0.9467 - val_loss: 0.1848\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9442 - loss: 0.1876 - val_accuracy: 0.9631 - val_loss: 0.1282\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9594 - loss: 0.1344 - val_accuracy: 0.9663 - val_loss: 0.1077\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.1096 - val_accuracy: 0.9710 - val_loss: 0.0966\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9720 - loss: 0.0920 - val_accuracy: 0.9726 - val_loss: 0.0870\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9762 - loss: 0.0785 - val_accuracy: 0.9735 - val_loss: 0.0858\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.0677 - val_accuracy: 0.9744 - val_loss: 0.0855\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9810 - loss: 0.0619 - val_accuracy: 0.9753 - val_loss: 0.0815\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0535 - val_accuracy: 0.9755 - val_loss: 0.0818\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.0487 - val_accuracy: 0.9749 - val_loss: 0.0829\n",
      "\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 16:34:06.579375: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 31360000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0731\n",
      "Test Accuracy: 0.9766\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\n",
      "First 5 predictions: [7 2 1 0 4]\n",
      "Actual labels: [7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "import numpy as np\n",
    "\n",
    "#Just to get you started, here's some data!\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Tensorflows data is from 0-255, so here we just normalize to the 0-1 range:\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Import necessary libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "import numpy as np\n",
    "\n",
    "# Check the data shape\n",
    "print(f\"Training data shape: {x_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {x_test.shape}\")\n",
    "\n",
    "# Build the model using Sequential API\n",
    "model = Sequential([\n",
    "    # Flatten 28x28 images to 784-dimensional vector\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    \n",
    "    # First hidden layer with 128 neurons and ReLU activation\n",
    "    Dense(128, activation='relu'),\n",
    "    \n",
    "    # Optional: Add dropout for regularization\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    # Second hidden layer with 64 neurons\n",
    "    Dense(64, activation='relu'),\n",
    "    \n",
    "    # Output layer with 10 neurons (one per digit) and softmax activation\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nTraining the model...\")\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_split=0.2,  # Use 20% of training data for validation\n",
    "    batch_size=128,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Make some predictions\n",
    "predictions = model.predict(x_test[:5])\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "print(f\"\\nFirst 5 predictions: {predicted_classes}\")\n",
    "print(f\"Actual labels: {y_test[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Multi-Input Networks for Mixed Data Types\n",
    "\n",
    "In this exercise, you'll build a network that processes both numerical and categorical data to predict car prices using the Auto MPG dataset. You'll implement different architectures for processing each type of data and combine them effectively.\n",
    "\n",
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m target_data = df[target]\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Split the data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m X_num_train_full, X_num_test, X_cat_train_full, X_cat_test, y_train_full, y_test = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnumeric_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m X_num_train, X_num_valid, X_cat_train, X_cat_valid, y_train, y_valid = train_test_split(\n\u001b[32m     36\u001b[39m     X_num_train_full, X_cat_train_full, y_train_full, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Scale numeric data\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2919\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2916\u001b[39m arrays = indexable(*arrays)\n\u001b[32m   2918\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m n_train, n_test = \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\n\u001b[32m   2921\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   2924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2499\u001b[39m, in \u001b[36m_validate_shuffle_split\u001b[39m\u001b[34m(n_samples, test_size, train_size, default_test_size)\u001b[39m\n\u001b[32m   2496\u001b[39m n_train, n_test = \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[32m   2498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2499\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2500\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maforementioned parameters.\u001b[39m\u001b[33m\"\u001b[39m.format(n_samples, test_size, train_size)\n\u001b[32m   2503\u001b[39m     )\n\u001b[32m   2505\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[31mValueError\u001b[39m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and prepare the Auto MPG dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
    "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin', 'Car Name']\n",
    "\n",
    "# Load the raw data\n",
    "df = pd.read_csv(url, names=column_names,\n",
    "                 na_values='?', comment='\\t',\n",
    "                 sep=' ', skipinitialspace=True)\n",
    "\n",
    "# Clean the data\n",
    "df = df.dropna()\n",
    "\n",
    "# Separate features\n",
    "numeric_features = ['Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration']\n",
    "categorical_features = ['Model Year', 'Origin']\n",
    "target = 'MPG'\n",
    "\n",
    "# Create inputs\n",
    "numeric_data = df[numeric_features]\n",
    "categorical_data = df[categorical_features]\n",
    "target_data = df[target]\n",
    "\n",
    "# Split the data\n",
    "X_num_train_full, X_num_test, X_cat_train_full, X_cat_test, y_train_full, y_test = train_test_split(\n",
    "    numeric_data, categorical_data, target_data, test_size=0.2, random_state=42)\n",
    "\n",
    "X_num_train, X_num_valid, X_cat_train, X_cat_valid, y_train, y_valid = train_test_split(\n",
    "    X_num_train_full, X_cat_train_full, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale numeric data\n",
    "scaler = StandardScaler()\n",
    "X_num_train_scaled = scaler.fit_transform(X_num_train)\n",
    "X_num_valid_scaled = scaler.transform(X_num_valid)\n",
    "X_num_test_scaled = scaler.transform(X_num_test)\n",
    "\n",
    "# Encode categorical data\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "X_cat_train_encoded = encoder.fit_transform(X_cat_train)\n",
    "X_cat_valid_encoded = encoder.transform(X_cat_valid)\n",
    "X_cat_test_encoded = encoder.transform(X_cat_test)\n",
    "\n",
    "# Utility function for plotting training history\n",
    "def plot_learning_curves(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    ax1.plot(history.history['loss'], label='Training Loss')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    ax2.plot(history.history['mape'], label='Training MAPE')\n",
    "    ax2.plot(history.history['val_mape'], label='Validation MAPE')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('MAPE')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1: Basic Multi-Input Model\n",
    "\n",
    "Create a basic multi-input model that processes numeric and categorical data separately:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (365258959.py, line 14)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mnumeric_input = Input(shape=(num_features,), name='numeric_input')\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def create_basic_multi_input_model(num_features, cat_features):\n",
    "    # TODO: Create a model with:\n",
    "    # - One input branch for numeric features\n",
    "    # - One input branch for categorical features\n",
    "    # - Dense layers for each branch\n",
    "    # - Concatenated outputs\n",
    "    # - Final prediction layer\n",
    "    # Return both the model and its inputs\n",
    "    return None, None\n",
    "\n",
    "# Create and compile the model\n",
    "num_features = X_num_train_scaled.shape[1]\n",
    "cat_features = X_cat_train_encoded.shape[1]\n",
    "\n",
    "model, inputs = create_basic_multi_input_model(num_features, cat_features)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mape'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [X_num_train_scaled, X_cat_train_encoded],\n",
    "    y_train,\n",
    "    validation_data=([X_num_valid_scaled, X_cat_valid_encoded], y_valid),\n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "plot_learning_curves(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11782/1619705464.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(url, names=column_names, delim_whitespace=True, na_values='?')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset size: 398\n",
      "Dataset size after dropping NAs: 392\n",
      "Training set size: 250\n",
      "Validation set size: 63\n",
      "Test set size: 79\n",
      "\n",
      "Number of numeric features: 5\n",
      "Number of categorical features (after encoding): 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ numeric_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ categorical_input   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ numeric_dense1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ numeric_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ categorical_dense1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │ categorical_inpu… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ numeric_dense2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ numeric_dense1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ categorical_dense2  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ categorical_dens… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ numeric_dense2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ categorical_dens… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ combined_dense1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ combined_dense2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ combined_dense1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ combined_dense2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ numeric_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ categorical_input   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ numeric_dense1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m384\u001b[0m │ numeric_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ categorical_dense1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │        \u001b[38;5;34m544\u001b[0m │ categorical_inpu… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ numeric_dense2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ numeric_dense1[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ categorical_dense2  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ categorical_dens… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ numeric_dense2[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ categorical_dens… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ combined_dense1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m1,568\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ combined_dense2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ combined_dense1[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m17\u001b[0m │ combined_dense2[\u001b[38;5;34m…\u001b[0m │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,649</span> (22.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,649\u001b[0m (22.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,649</span> (22.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,649\u001b[0m (22.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the model...\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 619.8752 - mape: 99.1500 - val_loss: 565.9280 - val_mape: 98.1368\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 594.3431 - mape: 96.8747 - val_loss: 538.3677 - val_mape: 95.4662\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 558.3317 - mape: 93.3214 - val_loss: 495.7460 - val_mape: 90.9180\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 501.8521 - mape: 87.0696 - val_loss: 430.1494 - val_mape: 83.2185\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 417.4608 - mape: 76.6606 - val_loss: 335.8651 - val_mape: 70.6820\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 299.5529 - mape: 59.8519 - val_loss: 217.1535 - val_mape: 52.1886\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 172.2742 - mape: 45.2555 - val_loss: 108.1933 - val_mape: 38.3261\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 74.2284 - mape: 33.9012 - val_loss: 48.8880 - val_mape: 26.9533\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 43.6232 - mape: 27.0927 - val_loss: 44.9168 - val_mape: 23.2501\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 38.6620 - mape: 23.2136 - val_loss: 37.7729 - val_mape: 18.5559\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.6024 - mape: 18.3905 - val_loss: 35.5656 - val_mape: 18.9763\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26.2791 - mape: 17.4257 - val_loss: 32.7336 - val_mape: 18.1003\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 23.4857 - mape: 16.6334 - val_loss: 28.2962 - val_mape: 16.0255\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 20.7161 - mape: 16.0027 - val_loss: 25.6188 - val_mape: 15.3560\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 19.5413 - mape: 15.7755 - val_loss: 23.8327 - val_mape: 14.7854\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 17.7952 - mape: 14.8090 - val_loss: 22.5983 - val_mape: 14.0858\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 16.6100 - mape: 13.7901 - val_loss: 21.4270 - val_mape: 13.6803\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.4518 - mape: 13.0726 - val_loss: 20.0315 - val_mape: 13.2559\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 14.5468 - mape: 12.7260 - val_loss: 18.7406 - val_mape: 13.0026\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 13.7134 - mape: 12.2871 - val_loss: 17.8639 - val_mape: 12.7561\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 12.9524 - mape: 11.7947 - val_loss: 17.0850 - val_mape: 12.5507\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12.2474 - mape: 11.4313 - val_loss: 16.3110 - val_mape: 12.3818\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.6673 - mape: 11.1589 - val_loss: 15.7010 - val_mape: 12.2210\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.1477 - mape: 10.8751 - val_loss: 15.1556 - val_mape: 12.1051\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.6989 - mape: 10.6582 - val_loss: 14.6590 - val_mape: 11.9262\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.3049 - mape: 10.4339 - val_loss: 14.3879 - val_mape: 11.8621\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8698 - mape: 10.2552 - val_loss: 13.7606 - val_mape: 11.6485\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5698 - mape: 10.1123 - val_loss: 13.5119 - val_mape: 11.5658\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.2361 - mape: 9.9016 - val_loss: 13.2230 - val_mape: 11.4951\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0008 - mape: 9.7701 - val_loss: 12.9560 - val_mape: 11.4108\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.7198 - mape: 9.6168 - val_loss: 12.6219 - val_mape: 11.3065\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4896 - mape: 9.5064 - val_loss: 12.3987 - val_mape: 11.2304\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.3082 - mape: 9.3839 - val_loss: 12.2305 - val_mape: 11.1568\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0793 - mape: 9.2768 - val_loss: 12.0161 - val_mape: 11.0425\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.9875 - mape: 9.2147 - val_loss: 11.7632 - val_mape: 10.9307\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8523 - mape: 9.1650 - val_loss: 11.6901 - val_mape: 10.9119\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.6660 - mape: 9.0376 - val_loss: 11.6665 - val_mape: 10.9108\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.6534 - mape: 8.9847 - val_loss: 11.4410 - val_mape: 10.7718\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.4280 - mape: 8.9344 - val_loss: 11.2001 - val_mape: 10.5855\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4290 - mape: 8.9198 - val_loss: 11.2271 - val_mape: 10.6359\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.3407 - mape: 8.8309 - val_loss: 11.2460 - val_mape: 10.7454\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2022 - mape: 8.7462 - val_loss: 10.9810 - val_mape: 10.4732\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2955 - mape: 8.8859 - val_loss: 10.9044 - val_mape: 10.3924\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2345 - mape: 8.7378 - val_loss: 11.0233 - val_mape: 10.7165\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1109 - mape: 8.7000 - val_loss: 10.5995 - val_mape: 10.2569\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.9567 - mape: 8.6199 - val_loss: 10.6545 - val_mape: 10.3430\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8840 - mape: 8.5299 - val_loss: 10.6055 - val_mape: 10.3498\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.8411 - mape: 8.4701 - val_loss: 10.4903 - val_mape: 10.3039\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7733 - mape: 8.4572 - val_loss: 10.3506 - val_mape: 10.1940\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7256 - mape: 8.4090 - val_loss: 10.2539 - val_mape: 10.1586\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test set...\n",
      "Test MSE Loss: 7.0556\n",
      "Test MAPE: 8.70%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\n",
      "Sample predictions vs actual:\n",
      "Predicted: 25.30 MPG, Actual: 26.00 MPG\n",
      "Predicted: 23.61 MPG, Actual: 21.60 MPG\n",
      "Predicted: 36.30 MPG, Actual: 36.10 MPG\n",
      "Predicted: 29.52 MPG, Actual: 26.00 MPG\n",
      "Predicted: 28.61 MPG, Actual: 27.00 MPG\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
    "\n",
    "# Load and prepare the Auto MPG dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
    "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin', 'Car Name']\n",
    "\n",
    "# Load the raw data with proper parameters\n",
    "df = pd.read_csv(url, names=column_names, delim_whitespace=True, na_values='?')\n",
    "\n",
    "print(f\"Initial dataset size: {len(df)}\")\n",
    "\n",
    "# Clean the data\n",
    "df = df.dropna()\n",
    "print(f\"Dataset size after dropping NAs: {len(df)}\")\n",
    "\n",
    "# Drop the car name column as it's not useful for prediction\n",
    "df = df.drop('Car Name', axis=1)\n",
    "\n",
    "# Separate features\n",
    "numeric_features = ['Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration']\n",
    "categorical_features = ['Model Year', 'Origin']\n",
    "target = 'MPG'\n",
    "\n",
    "# Create inputs\n",
    "numeric_data = df[numeric_features].values\n",
    "categorical_data = df[categorical_features].values\n",
    "target_data = df[target].values\n",
    "\n",
    "# Split the data\n",
    "X_num_train_full, X_num_test, X_cat_train_full, X_cat_test, y_train_full, y_test = train_test_split(\n",
    "    numeric_data, categorical_data, target_data, test_size=0.2, random_state=42)\n",
    "\n",
    "X_num_train, X_num_valid, X_cat_train, X_cat_valid, y_train, y_valid = train_test_split(\n",
    "    X_num_train_full, X_cat_train_full, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(X_num_train)}\")\n",
    "print(f\"Validation set size: {len(X_num_valid)}\")\n",
    "print(f\"Test set size: {len(X_num_test)}\")\n",
    "\n",
    "# Scale numeric data\n",
    "scaler = StandardScaler()\n",
    "X_num_train_scaled = scaler.fit_transform(X_num_train)\n",
    "X_num_valid_scaled = scaler.transform(X_num_valid)\n",
    "X_num_test_scaled = scaler.transform(X_num_test)\n",
    "\n",
    "# Encode categorical data\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_cat_train_encoded = encoder.fit_transform(X_cat_train)\n",
    "X_cat_valid_encoded = encoder.transform(X_cat_valid)\n",
    "X_cat_test_encoded = encoder.transform(X_cat_test)\n",
    "\n",
    "# Utility function for plotting training history\n",
    "def plot_learning_curves(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    ax1.plot(history.history['loss'], label='Training Loss')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    ax2.plot(history.history['mape'], label='Training MAPE')\n",
    "    ax2.plot(history.history['val_mape'], label='Validation MAPE')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('MAPE (%)')\n",
    "    ax2.set_title('Training and Validation MAPE')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "## Part 1: Basic Multi-Input Model\n",
    "\n",
    "def create_basic_multi_input_model(num_features, cat_features):\n",
    "    \"\"\"\n",
    "    Create a basic multi-input model that processes numeric and categorical data separately.\n",
    "    \n",
    "    Args:\n",
    "        num_features: Number of numeric features\n",
    "        cat_features: Number of categorical features (after one-hot encoding)\n",
    "    \n",
    "    Returns:\n",
    "        model: Compiled Keras model\n",
    "        inputs: List of input layers [numeric_input, categorical_input]\n",
    "    \"\"\"\n",
    "    # Input layer for numeric features\n",
    "    numeric_input = Input(shape=(num_features,), name='numeric_input')\n",
    "    \n",
    "    # Input layer for categorical features\n",
    "    categorical_input = Input(shape=(cat_features,), name='categorical_input')\n",
    "    \n",
    "    # Process numeric features through dense layers\n",
    "    numeric_branch = Dense(64, activation='relu', name='numeric_dense1')(numeric_input)\n",
    "    numeric_branch = Dense(32, activation='relu', name='numeric_dense2')(numeric_branch)\n",
    "    \n",
    "    # Process categorical features through dense layers\n",
    "    categorical_branch = Dense(32, activation='relu', name='categorical_dense1')(categorical_input)\n",
    "    categorical_branch = Dense(16, activation='relu', name='categorical_dense2')(categorical_branch)\n",
    "    \n",
    "    # Concatenate both branches\n",
    "    concatenated = Concatenate(name='concatenate')([numeric_branch, categorical_branch])\n",
    "    \n",
    "    # Additional dense layers after concatenation\n",
    "    x = Dense(32, activation='relu', name='combined_dense1')(concatenated)\n",
    "    x = Dense(16, activation='relu', name='combined_dense2')(x)\n",
    "    \n",
    "    # Output layer for regression (single value - MPG prediction)\n",
    "    output = Dense(1, name='output')(x)\n",
    "    \n",
    "    # Create the model\n",
    "    model = Model(inputs=[numeric_input, categorical_input], outputs=output)\n",
    "    \n",
    "    return model, [numeric_input, categorical_input]\n",
    "\n",
    "# Create and compile the model\n",
    "num_features = X_num_train_scaled.shape[1]\n",
    "cat_features = X_cat_train_encoded.shape[1]\n",
    "\n",
    "print(f\"\\nNumber of numeric features: {num_features}\")\n",
    "print(f\"Number of categorical features (after encoding): {cat_features}\")\n",
    "\n",
    "model, inputs = create_basic_multi_input_model(num_features, cat_features)\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mape'])\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nTraining the model...\")\n",
    "history = model.fit(\n",
    "    [X_num_train_scaled, X_cat_train_encoded],\n",
    "    y_train,\n",
    "    validation_data=([X_num_valid_scaled, X_cat_valid_encoded], y_valid),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot learning curves\n",
    "plot_learning_curves(history)\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_loss, test_mape = model.evaluate(\n",
    "    [X_num_test_scaled, X_cat_test_encoded], \n",
    "    y_test, \n",
    "    verbose=0\n",
    ")\n",
    "print(f\"Test MSE Loss: {test_loss:.4f}\")\n",
    "print(f\"Test MAPE: {test_mape:.2f}%\")\n",
    "\n",
    "# Make some predictions\n",
    "sample_predictions = model.predict([X_num_test_scaled[:5], X_cat_test_encoded[:5]])\n",
    "print(f\"\\nSample predictions vs actual:\")\n",
    "for i in range(5):\n",
    "    print(f\"Predicted: {sample_predictions[i][0]:.2f} MPG, Actual: {y_test[i]:.2f} MPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2: Enhanced Multi-Input Model with Different Branch Depths\n",
    "\n",
    "Create a more sophisticated model with different architectures for numeric and categorical data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_enhanced_multi_input_model(num_features, cat_features):\n",
    "    # TODO: Create a model with:\n",
    "    # - Deep branch for numeric features (3+ layers)\n",
    "    # - Shallow branch for categorical features (1-2 layers)\n",
    "    # - Batch normalization in numeric branch\n",
    "    # - Dropout in both branches\n",
    "    # - Skip connection in numeric branch\n",
    "    # Return both the model and its inputs\n",
    "    return None, None\n",
    "\n",
    "# Create and compile the enhanced model\n",
    "model_enhanced, inputs_enhanced = create_enhanced_multi_input_model(num_features, cat_features)\n",
    "model_enhanced.compile(optimizer='adam', loss='mse', metrics=['mape'])\n",
    "\n",
    "# Train the enhanced model\n",
    "history_enhanced = model_enhanced.fit(\n",
    "    [X_num_train_scaled, X_cat_train_encoded],\n",
    "    y_train,\n",
    "    validation_data=([X_num_valid_scaled, X_cat_valid_encoded], y_valid),\n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "plot_learning_curves(history_enhanced)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 3: Adding Auxiliary Outputs\n",
    "\n",
    "Modify your enhanced model to include auxiliary outputs for regularization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_multi_output_model(num_features, cat_features):\n",
    "    # TODO: Create a model with:\n",
    "    # - Similar structure to enhanced model\n",
    "    # - Auxiliary output from numeric branch\n",
    "    # - Auxiliary output from categorical branch\n",
    "    # - Main output from combined features\n",
    "    # Return model and inputs\n",
    "    return None, None\n",
    "\n",
    "# Create and compile the multi-output model\n",
    "model_multi_output, inputs_multi_output = create_multi_output_model(num_features, cat_features)\n",
    "model_multi_output.compile(\n",
    "    optimizer='adam',\n",
    "    loss=['mse', 'mse', 'mse'],\n",
    "    loss_weights=[0.7, 0.15, 0.15],\n",
    "    metrics=['mape']\n",
    ")\n",
    "\n",
    "# Train the multi-output model\n",
    "history_multi_output = model_multi_output.fit(\n",
    "    [X_num_train_scaled, X_cat_train_encoded],\n",
    "    [y_train, y_train, y_train],\n",
    "    validation_data=(\n",
    "        [X_num_valid_scaled, X_cat_valid_encoded],\n",
    "        [y_valid, y_valid, y_valid]\n",
    "    ),\n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "plot_learning_curves(history_multi_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 4: Model Comparison and Analysis\n",
    "\n",
    "Compare the performance of all three models:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compare_models(models, histories, X_test_data, y_test_data):\n",
    "    # TODO: Create a comparison including:\n",
    "    # - Test set performance\n",
    "    # - Training time\n",
    "    # - Number of parameters\n",
    "    # - Best validation performance\n",
    "    # Return a pandas DataFrame with results\n",
    "    return None\n",
    "\n",
    "# Example usage:\n",
    "models = {\n",
    "    'Basic': model,\n",
    "    'Enhanced': model_enhanced,\n",
    "    'Multi-Output': model_multi_output\n",
    "}\n",
    "\n",
    "histories = {\n",
    "    'Basic': history,\n",
    "    'Enhanced': history_enhanced,\n",
    "    'Multi-Output': history_multi_output\n",
    "}\n",
    "\n",
    "comparison_df = compare_models(\n",
    "    models, histories,\n",
    "    [X_num_test_scaled, X_cat_test_encoded],\n",
    "    y_test\n",
    ")\n",
    "print(comparison_df)\n",
    "\n",
    "# TODO: Create visualizations comparing:\n",
    "# 1. Learning curves for all models\n",
    "# 2. Prediction accuracy on test set\n",
    "# 3. Training time comparison\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
