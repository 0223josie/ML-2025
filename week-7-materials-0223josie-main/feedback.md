# Assignment Feedback: Week 7: Hyperparameter Tuning

**Student:** 0223josie
**Raw Score:** 18/21 (85.7%)
**Course Points Earned:** 4

---

## Problem Breakdown

### Exercise 1 (7/9 = 77.8%)

**Part ex1-part2** (ex1-part2.code): 2/2 points

_Feedback:_ Good use of grid.best_estimator_ and fit_predict to obtain labels, plus a clear comparison plot. This correctly leverages your prior GridSearchCV work. Ensure comparison_plot is defined/imported. Nice job.

**Part ex1-part3** (ex1-part3.code): 1/2 points

_Feedback:_ You correctly reuse scorer/cv and run a valid search, but you didn’t fulfill the task: no visualization. Extract best_estimator_, compute labels, and call comparison_plot(X, labels, y, ...). Also align with prior work (use your best model’s params) when plotting.

**Part ex1-part4** (ex1-part4.code): 2/2 points

_Feedback:_ Good job. You correctly leveraged your prior RandomizedSearchCV run, reported best params/score, extracted labels from the best estimator, and visualized results. Your prior setup used the same number of trials as GridSearch, meeting the requirement.

**Part ex1-part5** (ex1-part5.fill): 1/2 points

_Feedback:_ You implemented a functional Hyperopt search and computed ARI; good effort. However, the task here was to visualize your best results. You didn’t produce any plot. After selecting best params, compute labels and call comparison_plot(X, best_labels, y, ...).

**Part ex1-part6** (ex1-part6.code): 1/1 points

_Feedback:_ Good job applying Hyperopt results: you refit HDBSCAN with best_params, generated labels, plotted, and reported ARI. This correctly uses prior Hyperopt work and completes the optimization workflow.

---

### Exercise 2 (11/12 = 91.7%)

**Part ex2-part1** (ex2-part1.code): 2/2 points

_Feedback:_ Good job: you sampled by label, embedded with SBERT, explored multiple UMAP configs, and optimized HDBSCAN with Hyperopt. This matches the intended approach. For completeness, consider printing coverage/coherence and basic cluster stats to interpret results.

**Part ex2-part2** (ex2-part2.fill): 2/2 points

_Feedback:_ Well done. You replaced the TODO with a functional helper: it locates cluster members, prints size and coherence, and samples sentences reproducibly. Formatting differs from example but meets requirements. Minor: using a local RNG (random.Random) would avoid global seeding.

**Part ex2-part3** (ex2-part3.fill): 2/2 points

_Feedback:_ Good job. You implemented sample_clusters correctly: converts labels to np array, excludes noise, ranks by size or coherence, and calls inspect_cluster for top clusters. Minor note: when ranking by coherence, ensure keys align with existing clusters (they do here).

**Part ex2-part4** (ex2-part4.fill): 1/2 points

_Feedback:_ Good effort: you filter noise, pick top-N by size, compute counts, and plot. However, you normalize by cluster totals, showing cluster composition, not prevalence within each newsgroup. Normalize by group totals to reflect per-group proportions as requested.

**Part ex2-part4** (ex2-part4.code): 2/2 points

_Feedback:_ Good job: you map best_labels to df_sampled and call visualize_cluster_profiles with top_n and aligned labels/targets, which addresses the visualization requirement. To complete the task, also use inspect_cluster on notably different/similar clusters across groups.

**Part ex2-part5** (ex2-part5.answer): 2/2 points

_Feedback:_ Good, thoughtful reflections. You described preprocessing choices and their effects, reasonable criteria for “good” clusters, and plausible group differences. Minor: clarify what you mean by a “uniform” bar (dominance vs mix) and tie judgments to your coverage/coherence metrics and specific clusters.

---

## Additional Information

This feedback was automatically generated by the autograder using LLM-based evaluation.

**Generated:** 2025-11-11 22:35:18 UTC

If you have questions about your grade, please reach out to the instructor.

---

*Powered by [Grade-Lite](https://github.com/your-repo/grade-lite) Autograder*