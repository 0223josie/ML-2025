{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a1cdd6",
   "metadata": {
    "problem_id": "ex1"
   },
   "source": [
    "## **Exercise 1**\n",
    "<!-- @q -->\n",
    "\n",
    "In the following exercises, we'll explore the behavior of different ensemble methods from the notes. First, we'll set up some synthetic data to play with.  I've included a decision tree classifier to provide you with a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1d31fef",
   "metadata": {
    "part_id": "ex1-part1",
    "span": "ex1-part1.code",
    "student": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate synthetic dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=400, n_features=20, n_informative=2, n_redundant=15, n_classes=2, random_state=42, flip_y=0.07\n",
    ")\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a decision tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "single_tree_scores = cross_val_score(clf,X,y,cv=5)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f\"Test Accuracy: {single_tree_scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01d1c1a",
   "metadata": {
    "part_id": "ex1-part2"
   },
   "source": [
    "### **Exercise 1.1**\n",
    "\n",
    "Implement a bagging classifier with 10 decision tree estimators, and compare performance to the single decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9e7cddd",
   "metadata": {
    "part_id": "ex1-part2",
    "span": "ex1-part2.code",
    "student": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Decision Tree CV Accuracy: 0.83\n",
      "Bagging Classifier CV Accuracy: 0.88\n",
      "Improvement: 0.05\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.ensemble import BaggingClassifier  # Add this import\n",
    "from sklearn.model_selection import train_test_split  # Add this import\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=400, n_features=20, n_informative=2, n_redundant=15, n_classes=2, random_state=42, flip_y=0.07\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "single_tree_scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "print(f\"Single Decision Tree CV Accuracy: {single_tree_scores.mean():.2f}\")\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    n_estimators=10,\n",
    "    random_state=42\n",
    ")\n",
    "bagging_scores = cross_val_score(bag_clf, X, y, cv=5)\n",
    "\n",
    "print(f\"Bagging Classifier CV Accuracy: {bagging_scores.mean():.2f}\")\n",
    "print(f\"Improvement: {bagging_scores.mean() - single_tree_scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf364693",
   "metadata": {
    "part_id": "ex1-part3"
   },
   "source": [
    "### **Exercise 1.2: Effect of Subsampling in Bagging**\n",
    "\n",
    "\n",
    "__Task:__\n",
    "\n",
    "- Train a BaggingClassifier with different max_samples values (30%, 50%, 70% and 100%) and compare how subsampling affects the model’s performance on the test set.\n",
    "- Use 10 base estimators as in Exercise 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4867954e",
   "metadata": {
    "part_id": "ex1-part3",
    "span": "ex1-part3.code",
    "student": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== max_samples = 30% ===\n",
      "Bagging Decision Tree CV Accuracy: 0.8975 (+/- 0.0310)\n",
      "Bagging Logistic Regression CV Accuracy: 0.8875 (+/- 0.0335)\n",
      "\n",
      "=== max_samples = 50% ===\n",
      "Bagging Decision Tree CV Accuracy: 0.8950 (+/- 0.0269)\n",
      "Bagging Logistic Regression CV Accuracy: 0.8925 (+/- 0.0312)\n",
      "\n",
      "=== max_samples = 70% ===\n",
      "Bagging Decision Tree CV Accuracy: 0.8775 (+/- 0.0414)\n",
      "Bagging Logistic Regression CV Accuracy: 0.8950 (+/- 0.0322)\n",
      "\n",
      "=== max_samples = 100% ===\n",
      "Bagging Decision Tree CV Accuracy: 0.8825 (+/- 0.0203)\n",
      "Bagging Logistic Regression CV Accuracy: 0.8850 (+/- 0.0366)\n",
      "\n",
      "=== Summary Table ===\n",
      "  max_samples  Tree_CV_Mean  Tree_CV_Std  LogReg_CV_Mean  LogReg_CV_Std\n",
      "0         30%        0.8975     0.031024          0.8875       0.033541\n",
      "1         50%        0.8950     0.026926          0.8925       0.031225\n",
      "2         70%        0.8775     0.041382          0.8950       0.032210\n",
      "3        100%        0.8825     0.020310          0.8850       0.036572\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "max_samples_values = [0.3, 0.5, 0.7, 1.0]\n",
    "results = []\n",
    "\n",
    "for max_sample in max_samples_values:\n",
    "    bag_tree = BaggingClassifier(\n",
    "        DecisionTreeClassifier(random_state=42), \n",
    "        n_estimators=10, \n",
    "        random_state=42,\n",
    "        max_samples=max_sample\n",
    "    )\n",
    "    bag_tree_scores = cross_val_score(bag_tree, X, y, cv=5)\n",
    "    bag_log = BaggingClassifier(\n",
    "        LogisticRegression(random_state=42, max_iter=1000), \n",
    "        n_estimators=10, \n",
    "        random_state=42,\n",
    "        max_samples=max_sample\n",
    "    )\n",
    "    bag_log_scores = cross_val_score(bag_log, X, y, cv=5)\n",
    "    \n",
    "    results.append({\n",
    "        'max_samples': f\"{int(max_sample*100)}%\",\n",
    "        'Tree_CV_Mean': bag_tree_scores.mean(),\n",
    "        'Tree_CV_Std': bag_tree_scores.std(),\n",
    "        'LogReg_CV_Mean': bag_log_scores.mean(),\n",
    "        'LogReg_CV_Std': bag_log_scores.std()\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n=== max_samples = {int(max_sample*100)}% ===\")\n",
    "    print(f\"Bagging Decision Tree CV Accuracy: {bag_tree_scores.mean():.4f} (+/- {bag_tree_scores.std():.4f})\")\n",
    "    print(f\"Bagging Logistic Regression CV Accuracy: {bag_log_scores.mean():.4f} (+/- {bag_log_scores.std():.4f})\")\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n=== Summary Table ===\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762fbe13",
   "metadata": {},
   "source": [
    "### **Exercise 1.3: Out-of-Bag (OOB) Evaluation**\n",
    "\n",
    "<!-- @sub-->\n",
    "\n",
    "**Task:**\n",
    "\n",
    "- Enable Out-of-Bag (OOB) evaluation in the BaggingClassifier and compare the OOB score to the test set accuracy.\n",
    "- Train the model using 10 base estimators and the same synthetic dataset as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df86b89f",
   "metadata": {
    "part_id": "ex1-part3",
    "span": "ex1-part3.code",
    "student": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Out-of-Bag Evaluation ===\n",
      "OOB Score: 0.8571\n",
      "Test Set Accuracy: 0.8667\n",
      "Difference: 0.0095\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "bag_tree_oob = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    n_estimators=10,\n",
    "    random_state=42,\n",
    "    oob_score=True\n",
    ")\n",
    "\n",
    "bag_tree_oob.fit(X_train, y_train)\n",
    "\n",
    "oob_score = bag_tree_oob.oob_score_\n",
    "\n",
    "y_pred_test = bag_tree_oob.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"=== Out-of-Bag Evaluation ===\")\n",
    "print(f\"OOB Score: {oob_score:.4f}\")\n",
    "print(f\"Test Set Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Difference: {abs(oob_score - test_accuracy):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051799cd",
   "metadata": {
    "part_id": "ex1-part4"
   },
   "source": [
    "### **Exercise 1.4: Implementing AdaBoost**\n",
    "\n",
    "\n",
    "**Task:**  \n",
    "- Train an `AdaBoostClassifier` using 10 estimators and a learning rate of 1.\n",
    "- Use the synthetic dataset from earlier exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41cb71d2",
   "metadata": {
    "part_id": "ex1-part4",
    "span": "ex1-part4.code",
    "student": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.9075 (+/- 0.0232)\n",
      "Single Decision Tree CV Accuracy: 0.8300\n",
      "Bagging Classifier CV Accuracy: 0.8825\n",
      "AdaBoost CV Accuracy: 0.9075\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1, random_state=42),  # Weak learner (stump)\n",
    "    n_estimators=10,\n",
    "    learning_rate=1.0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ada_scores = cross_val_score(ada_clf, X, y, cv=5)\n",
    "print(f\"CV Accuracy: {ada_scores.mean():.4f} (+/- {ada_scores.std():.4f})\")\n",
    "single_tree_scores = cross_val_score(DecisionTreeClassifier(random_state=42), X, y, cv=5)\n",
    "print(f\"Single Decision Tree CV Accuracy: {single_tree_scores.mean():.4f}\")\n",
    "bag_scores = cross_val_score(\n",
    "    BaggingClassifier(DecisionTreeClassifier(random_state=42), n_estimators=10, random_state=42), \n",
    "    X, y, cv=5\n",
    ")\n",
    "print(f\"Bagging Classifier CV Accuracy: {bag_scores.mean():.4f}\")\n",
    "print(f\"AdaBoost CV Accuracy: {ada_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68b8cbb",
   "metadata": {
    "part_id": "ex1-part5"
   },
   "source": [
    "### **Exercise 1.5: Effect of Hyperparameters in AdaBoost**\n",
    "\n",
    "\n",
    "**Task:**  \n",
    "- Sweep the learning rate parameters from .5 to 2 in increments of .25, and the number of estimators from 5 to 55 in increments of 10. Use cross validation with accuracy to evaluate performance. \n",
    "- Use GridSearchCV for your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3468ee5",
   "metadata": {
    "part_id": "ex1-part5",
    "span": "ex1-part5.code",
    "student": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Grid Search Results ===\n",
      "Best Parameters: {'learning_rate': np.float64(1.0), 'n_estimators': np.int64(15)}\n",
      "Best Cross-Validation Score: 0.9071\n",
      "Test Set Accuracy: 0.8750\n",
      "\n",
      "=== Top 5 Parameter Combinations ===\n",
      "    param_learning_rate  param_n_estimators  mean_test_score\n",
      "13                 1.00                  15         0.907143\n",
      "16                 1.00                  45         0.900000\n",
      "15                 1.00                  35         0.896429\n",
      "12                 1.00                   5         0.896429\n",
      "6                  0.75                   5         0.896429\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': np.arange(0.5, 2.25, 0.25),  # 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0\n",
    "    'n_estimators': np.arange(5, 65, 10)  # 5, 15, 25, 35, 45, 55\n",
    "}\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1, random_state=42),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    ada_clf,\n",
    "    param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"=== Grid Search Results ===\")\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "y_pred_best = grid_search.best_estimator_.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_best)\n",
    "print(f\"Test Set Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "top_5 = results_df[['param_learning_rate', 'param_n_estimators', 'mean_test_score']].sort_values(\n",
    "    'mean_test_score', ascending=False\n",
    ").head(5)\n",
    "print(\"\\n=== Top 5 Parameter Combinations ===\")\n",
    "print(top_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803bf8e6",
   "metadata": {},
   "source": [
    "<!-- @ sub -->\n",
    "Which parameters perform best? Which are the worst?  Do your results surprise you?  Why do you think you are seeing what you do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c252eb",
   "metadata": {
    "part_id": "ex1-part5",
    "span": "ex1-part5.answer",
    "student": true
   },
   "source": [
    "*Enter your answer in this cell*\n",
    "The best parameters are learning_rate=1.0 with n_estimators=15, achieving 90.7% CV accuracy. Surprisingly, higher learning rates consistently outperform lower ones, and fewer trees work better than more - increasing from 15 to 45 estimators actually decreases performance. This suggests overfitting with too many iterations at high learning rates. The results are counterintuitive because conventional wisdom favors lower learning rates with more estimators, but this simpler dataset doesn't require extensive boosting. Lower learning rates likely underperform because the grid doesn't test them with enough estimators (e.g., 0.1 learning rate needs 100+ trees, not just 5-45). This highlights that parameters must be tuned together - low learning rates paired with few estimators take tiny steps and stop before learning effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df56198b",
   "metadata": {
    "problem_id": "ex2"
   },
   "source": [
    "# **Exercise 2: Gradient Boosting for Regression**\n",
    "\n",
    "\n",
    "- Use `sklearn.ensemble.GradientBoostingRegressor` to implement a regression model on the following dataset.\n",
    "- Use a single train / test split\n",
    "- Train the model with 50 estimators and compare its performance to a decision tree regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c15b2b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @SHOW\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generate synthetic regression dataset\n",
    "X_reg, y_reg = make_regression(n_samples=1000, n_features=2, noise=0.1, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8cd8251",
   "metadata": {
    "part_id": "ex2-part1",
    "span": "ex2-part1.code",
    "student": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MODEL PERFORMANCE COMPARISON\n",
      "============================================================\n",
      "\n",
      "Gradient Boosting Regressor (50 estimators):\n",
      "  Mean Squared Error: 5.6205\n",
      "  R² Score: 0.9964\n",
      "\n",
      "Decision Tree Regressor:\n",
      "  Mean Squared Error: 6.1143\n",
      "  R² Score: 0.9961\n",
      "\n",
      "============================================================\n",
      "IMPROVEMENT\n",
      "============================================================\n",
      "MSE Improvement: 8.08%\n",
      "Gradient Boosting performs better than Decision Tree\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "# Create train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train Gradient Boosting Regressor with 50 estimators\n",
    "gb_regressor = GradientBoostingRegressor(n_estimators=50, random_state=42)\n",
    "gb_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Train Decision Tree Regressor for comparison\n",
    "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
    "dt_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "gb_predictions = gb_regressor.predict(X_test)\n",
    "dt_predictions = dt_regressor.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "gb_mse = mean_squared_error(y_test, gb_predictions)\n",
    "dt_mse = mean_squared_error(y_test, dt_predictions)\n",
    "\n",
    "gb_r2 = r2_score(y_test, gb_predictions)\n",
    "dt_r2 = r2_score(y_test, dt_predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nGradient Boosting Regressor (50 estimators):\")\n",
    "print(f\"  Mean Squared Error: {gb_mse:.4f}\")\n",
    "print(f\"  R² Score: {gb_r2:.4f}\")\n",
    "\n",
    "print(\"\\nDecision Tree Regressor:\")\n",
    "print(f\"  Mean Squared Error: {dt_mse:.4f}\")\n",
    "print(f\"  R² Score: {dt_r2:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMPROVEMENT\")\n",
    "print(\"=\"*60)\n",
    "mse_improvement = ((dt_mse - gb_mse) / dt_mse) * 100\n",
    "print(f\"MSE Improvement: {mse_improvement:.2f}%\")\n",
    "print(f\"Gradient Boosting performs {'better' if gb_mse < dt_mse else 'worse'} than Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c8b35a",
   "metadata": {
    "problem_id": "ex3"
   },
   "source": [
    "# **Exercise 3**\n",
    "\n",
    "<!-- @q -->\n",
    "\n",
    "Previously, we used hyperparameter optimization to optimize clustering.  Here, we will use it to optimize a random forest classifier.   I've started the process by organizing the data and establishing a baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "002c3e01",
   "metadata": {
    "part_id": "ex3-part1",
    "span": "ex3-part1.code",
    "student": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.8543\n"
     ]
    }
   ],
   "source": [
    "# @SHOW\n",
    "\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: Load Dataset and Preprocess\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', \n",
    "                'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', \n",
    "                'hours-per-week', 'native-country', 'income']\n",
    "data = pd.read_csv(url, names=column_names, na_values=' ?')\n",
    "\n",
    "# Handle missing values by dropping rows with missing data\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Convert categorical columns to dummy variables\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop('income_ >50K', axis=1)\n",
    "y = data['income_ >50K']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Train Baseline Random Forest Model\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "baseline_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Baseline Accuracy: {baseline_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c668c1d2",
   "metadata": {
    "part_id": "ex3-part2"
   },
   "source": [
    "#### Step 1: GridSearchCV\n",
    "\n",
    "\n",
    "Implement run a grid search (using GridSearchCV) over a range of parameters for the random forest on the previously established data.  Test at least 18 different parameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e8405",
   "metadata": {
    "part_id": "ex3-part2",
    "span": "ex3-part2.code",
    "student": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BASELINE MODEL\n",
      "======================================================================\n",
      "Baseline Accuracy: 0.8543\n",
      "\n",
      "======================================================================\n",
      "GRID SEARCH OPTIMIZATION\n",
      "======================================================================\n",
      "Testing 36 parameter combinations...\n",
      "\n",
      "Running Grid Search (this may take a few minutes)...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "======================================================================\n",
      "BEST PARAMETERS FOUND\n",
      "======================================================================\n",
      "max_depth: None\n",
      "min_samples_leaf: 2\n",
      "min_samples_split: 10\n",
      "n_estimators: 100\n",
      "\n",
      "======================================================================\n",
      "MODEL PERFORMANCE COMPARISON\n",
      "======================================================================\n",
      "Baseline Accuracy:        0.8543\n",
      "Best Cross-Val Accuracy:  0.8607\n",
      "Optimized Test Accuracy:  0.8618\n",
      "\n",
      "Improvement: 0.87%\n",
      "\n",
      "======================================================================\n",
      "TOP 5 PARAMETER COMBINATIONS\n",
      "======================================================================\n",
      "\n",
      "Rank 1: Score = 0.8607\n",
      "  Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "\n",
      "Rank 2: Score = 0.8603\n",
      "  Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "\n",
      "Rank 3: Score = 0.8592\n",
      "  Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "\n",
      "Rank 4: Score = 0.8591\n",
      "  Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "\n",
      "Rank 5: Score = 0.8591\n",
      "  Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 3: GridSearchCV for Hyperparameter Optimization\n",
    "print(\"=\"*70)\n",
    "print(\"GRID SEARCH OPTIMIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define parameter grid - This creates 2 x 3 x 3 x 2 = 36 combinations\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],           # Number of trees\n",
    "    'max_depth': [10, 20, None],          # Maximum depth of trees\n",
    "    'min_samples_split': [2, 5, 10],      # Minimum samples to split a node\n",
    "    'min_samples_leaf': [1, 2]            # Minimum samples at leaf node\n",
    "}\n",
    "\n",
    "# Calculate total combinations\n",
    "total_combinations = 1\n",
    "for param_values in param_grid.values():\n",
    "    total_combinations *= len(param_values)\n",
    "print(f\"Testing {total_combinations} parameter combinations...\\n\")\n",
    "\n",
    "# Initialize GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                    # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,              # Use all available cores\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the grid search\n",
    "print(\"Running Grid Search (this may take a few minutes)...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Display Results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BEST PARAMETERS FOUND\")\n",
    "print(\"=\"*70)\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Baseline Accuracy:        {baseline_accuracy:.4f}\")\n",
    "print(f\"Best Cross-Val Accuracy:  {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_optimized = best_model.predict(X_test)\n",
    "optimized_accuracy = accuracy_score(y_test, y_pred_optimized)\n",
    "print(f\"Optimized Test Accuracy:  {optimized_accuracy:.4f}\")\n",
    "\n",
    "# Calculate improvement\n",
    "improvement = (optimized_accuracy - baseline_accuracy) / baseline_accuracy * 100\n",
    "print(f\"\\nImprovement: {improvement:.2f}%\")\n",
    "\n",
    "# Display top 5 parameter combinations\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TOP 5 PARAMETER COMBINATIONS\")\n",
    "print(\"=\"*70)\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "top_5 = results_df.nsmallest(5, 'rank_test_score')[['params', 'mean_test_score', 'rank_test_score']]\n",
    "for idx, row in top_5.iterrows():\n",
    "    print(f\"\\nRank {int(row['rank_test_score'])}: Score = {row['mean_test_score']:.4f}\")\n",
    "    print(f\"  Parameters: {row['params']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7977c9",
   "metadata": {
    "part_id": "ex3-part3"
   },
   "source": [
    "#### Step 2: RandomizedSearchCV\n",
    "\n",
    "\n",
    "Implement run a random search (using RandomSearchCV) over a range of parameters for the random forest.  Test at least 20 different parameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0382838",
   "metadata": {
    "part_id": "ex3-part3",
    "span": "ex3-part3.code",
    "student": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BASELINE MODEL\n",
      "======================================================================\n",
      "Baseline Accuracy: 0.8543\n",
      "\n",
      "======================================================================\n",
      "RANDOMIZED SEARCH OPTIMIZATION\n",
      "======================================================================\n",
      "Testing 25 random parameter combinations...\n",
      "\n",
      "Running Randomized Search (this may take a few minutes)...\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "\n",
      "======================================================================\n",
      "BEST PARAMETERS FOUND\n",
      "======================================================================\n",
      "bootstrap: False\n",
      "criterion: gini\n",
      "max_depth: None\n",
      "max_features: sqrt\n",
      "min_samples_leaf: 2\n",
      "min_samples_split: 13\n",
      "n_estimators: 207\n",
      "\n",
      "======================================================================\n",
      "MODEL PERFORMANCE COMPARISON\n",
      "======================================================================\n",
      "Baseline Accuracy:        0.8543\n",
      "Best Cross-Val Accuracy:  0.8603\n",
      "Optimized Test Accuracy:  0.8619\n",
      "\n",
      "Improvement: 0.89%\n",
      "\n",
      "======================================================================\n",
      "TOP 5 PARAMETER COMBINATIONS\n",
      "======================================================================\n",
      "\n",
      "Rank 1: Score = 0.8603\n",
      "  Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 13, 'n_estimators': 207}\n",
      "\n",
      "Rank 2: Score = 0.8592\n",
      "  Parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': 15, 'max_features': None, 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 153}\n",
      "\n",
      "Rank 3: Score = 0.8591\n",
      "  Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 13, 'n_estimators': 153}\n",
      "\n",
      "Rank 4: Score = 0.8586\n",
      "  Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 11, 'n_estimators': 269}\n",
      "\n",
      "Rank 5: Score = 0.8584\n",
      "  Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 25, 'max_features': None, 'min_samples_leaf': 8, 'min_samples_split': 8, 'n_estimators': 171}\n",
      "\n",
      "======================================================================\n",
      "SEARCH STATISTICS\n",
      "======================================================================\n",
      "Total combinations tested: 25\n",
      "Best score achieved: 0.8603\n",
      "Mean score across all trials: 0.8500\n",
      "Standard deviation: 0.0096\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.stats import randint, uniform\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 3: RandomizedSearchCV for Hyperparameter Optimization\n",
    "print(\"=\"*70)\n",
    "print(\"RANDOMIZED SEARCH OPTIMIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define parameter distributions for random sampling\n",
    "# This allows exploring a much wider range than GridSearch\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(50, 300),              # Random integers between 50-300\n",
    "    'max_depth': [5, 10, 15, 20, 25, None],        # Discrete options including no limit\n",
    "    'min_samples_split': randint(2, 20),           # Random integers between 2-20\n",
    "    'min_samples_leaf': randint(1, 10),            # Random integers between 1-10\n",
    "    'max_features': ['sqrt', 'log2', None],        # Feature selection strategies\n",
    "    'bootstrap': [True, False],                    # Whether to use bootstrap samples\n",
    "    'criterion': ['gini', 'entropy']               # Splitting criteria\n",
    "}\n",
    "\n",
    "n_iter = 25  # Number of random combinations to test\n",
    "print(f\"Testing {n_iter} random parameter combinations...\\n\")\n",
    "\n",
    "# Initialize RandomizedSearchCV with 5-fold cross-validation\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=n_iter,          # Number of parameter settings sampled\n",
    "    cv=5,                   # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,              # Use all available cores\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the random search\n",
    "print(\"Running Randomized Search (this may take a few minutes)...\")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Display Results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BEST PARAMETERS FOUND\")\n",
    "print(\"=\"*70)\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Baseline Accuracy:        {baseline_accuracy:.4f}\")\n",
    "print(f\"Best Cross-Val Accuracy:  {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred_optimized = best_model.predict(X_test)\n",
    "optimized_accuracy = accuracy_score(y_test, y_pred_optimized)\n",
    "print(f\"Optimized Test Accuracy:  {optimized_accuracy:.4f}\")\n",
    "\n",
    "# Calculate improvement\n",
    "improvement = (optimized_accuracy - baseline_accuracy) / baseline_accuracy * 100\n",
    "print(f\"\\nImprovement: {improvement:.2f}%\")\n",
    "\n",
    "# Display top 5 parameter combinations\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TOP 5 PARAMETER COMBINATIONS\")\n",
    "print(\"=\"*70)\n",
    "results_df = pd.DataFrame(random_search.cv_results_)\n",
    "top_5 = results_df.nsmallest(5, 'rank_test_score')[['params', 'mean_test_score', 'rank_test_score']]\n",
    "for idx, row in top_5.iterrows():\n",
    "    print(f\"\\nRank {int(row['rank_test_score'])}: Score = {row['mean_test_score']:.4f}\")\n",
    "    print(f\"  Parameters: {row['params']}\")\n",
    "\n",
    "# Additional statistics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SEARCH STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total combinations tested: {len(results_df)}\")\n",
    "print(f\"Best score achieved: {random_search.best_score_:.4f}\")\n",
    "print(f\"Mean score across all trials: {results_df['mean_test_score'].mean():.4f}\")\n",
    "print(f\"Standard deviation: {results_df['mean_test_score'].std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1828bcc",
   "metadata": {
    "part_id": "ex3-part4"
   },
   "source": [
    "#### Step 3: BayesianSearchCV\n",
    "\n",
    "\n",
    "\n",
    "Previously, we used HyperOpt for Bayesian optimization. The [bayesian-optimization](https://pypi.org/project/bayesian-optimization/) does much the same thing, but is a little more user friendly. Install the package and use it to run a Bayesian search over a range of parameters for the random forest.  Test at least 15 different parameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18c18cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bayesian-optimization\n",
      "  Downloading bayesian_optimization-3.1.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama>=0.4.6 in /home/codespace/.local/lib/python3.12/site-packages (from bayesian-optimization) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.25 in /home/codespace/.local/lib/python3.12/site-packages (from bayesian-optimization) (2.3.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from bayesian-optimization) (1.7.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from bayesian-optimization) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn>=1.0.0->bayesian-optimization) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn>=1.0.0->bayesian-optimization) (3.6.0)\n",
      "Downloading bayesian_optimization-3.1.0-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: bayesian-optimization\n",
      "Successfully installed bayesian-optimization-3.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e20e38",
   "metadata": {
    "part_id": "ex3-part4",
    "span": "ex3-part4.code",
    "student": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BASELINE MODEL\n",
      "======================================================================\n",
      "Baseline Accuracy: 0.8543\n",
      "\n",
      "======================================================================\n",
      "BAYESIAN OPTIMIZATION\n",
      "======================================================================\n",
      "\n",
      "Running Bayesian Optimization for 20 iterations...\n",
      "(This uses smart sampling to find optimal parameters efficiently)\n",
      "\n",
      "|   iter    |  target   | n_esti... | max_depth | min_sa... | min_sa... | max_fe... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.8602926\u001b[39m | \u001b[39m143.63502\u001b[39m | \u001b[39m28.767857\u001b[39m | \u001b[39m15.175890\u001b[39m | \u001b[39m6.3879263\u001b[39m | \u001b[39m0.2404167\u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m0.8500558\u001b[39m | \u001b[39m88.998630\u001b[39m | \u001b[39m6.4520903\u001b[39m | \u001b[39m17.591170\u001b[39m | \u001b[39m6.4100351\u001b[39m | \u001b[39m0.7372653\u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.8596296\u001b[39m | \u001b[39m55.146123\u001b[39m | \u001b[39m29.247746\u001b[39m | \u001b[39m16.983967\u001b[39m | \u001b[39m2.9110519\u001b[39m | \u001b[39m0.2636424\u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.8583033\u001b[39m | \u001b[39m95.851127\u001b[39m | \u001b[39m12.606056\u001b[39m | \u001b[39m11.445615\u001b[39m | \u001b[39m4.8875051\u001b[39m | \u001b[39m0.3621062\u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.8554436\u001b[39m | \u001b[39m202.96322\u001b[39m | \u001b[39m8.4873465\u001b[39m | \u001b[39m7.2586036\u001b[39m | \u001b[39m4.2972565\u001b[39m | \u001b[39m0.5104629\u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.8453313\u001b[39m | \u001b[39m201.88621\u001b[39m | \u001b[39m5.1334785\u001b[39m | \u001b[39m16.138010\u001b[39m | \u001b[39m6.6847617\u001b[39m | \u001b[39m0.5056514\u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.8600440\u001b[39m | \u001b[39m148.84767\u001b[39m | \u001b[39m19.768017\u001b[39m | \u001b[39m7.1306080\u001b[39m | \u001b[39m5.1358126\u001b[39m | \u001b[39m0.2821273\u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.8599611\u001b[39m | \u001b[39m144.40574\u001b[39m | \u001b[39m28.101196\u001b[39m | \u001b[39m14.224541\u001b[39m | \u001b[39m6.3090171\u001b[39m | \u001b[39m0.3734187\u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.8560652\u001b[39m | \u001b[39m138.93208\u001b[39m | \u001b[39m18.602395\u001b[39m | \u001b[39m15.460815\u001b[39m | \u001b[39m4.9474752\u001b[39m | \u001b[39m0.1      \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m0.8585934\u001b[39m | \u001b[39m156.30433\u001b[39m | \u001b[39m25.466320\u001b[39m | \u001b[39m11.801326\u001b[39m | \u001b[39m1.9854185\u001b[39m | \u001b[39m0.1524327\u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.8597539\u001b[39m | \u001b[39m150.49010\u001b[39m | \u001b[39m29.321339\u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m7.8130371\u001b[39m | \u001b[39m0.8251287\u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.8589664\u001b[39m | \u001b[39m158.40579\u001b[39m | \u001b[39m18.980020\u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m0.5852935\u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.8568113\u001b[39m | \u001b[39m136.60727\u001b[39m | \u001b[39m30.0     \u001b[39m | \u001b[39m4.0987954\u001b[39m | \u001b[39m8.3671672\u001b[39m | \u001b[39m0.1      \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m0.8595881\u001b[39m | \u001b[39m103.06775\u001b[39m | \u001b[39m18.511223\u001b[39m | \u001b[39m2.9772863\u001b[39m | \u001b[39m2.9560991\u001b[39m | \u001b[39m0.5386201\u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m0.8602098\u001b[39m | \u001b[39m103.05070\u001b[39m | \u001b[39m24.391106\u001b[39m | \u001b[39m12.779406\u001b[39m | \u001b[39m8.5234419\u001b[39m | \u001b[39m0.3471443\u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m0.8564798\u001b[39m | \u001b[39m93.739508\u001b[39m | \u001b[39m28.278060\u001b[39m | \u001b[39m7.3657169\u001b[39m | \u001b[39m2.3719224\u001b[39m | \u001b[39m0.7759836\u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m0.8583862\u001b[39m | \u001b[39m110.46603\u001b[39m | \u001b[39m15.014292\u001b[39m | \u001b[39m12.404931\u001b[39m | \u001b[39m6.8400076\u001b[39m | \u001b[39m0.2252639\u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m0.8577645\u001b[39m | \u001b[39m111.02507\u001b[39m | \u001b[39m29.097496\u001b[39m | \u001b[39m3.8585656\u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m0.6012028\u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m0.8602512\u001b[39m | \u001b[39m54.089165\u001b[39m | \u001b[39m29.969684\u001b[39m | \u001b[39m3.8985729\u001b[39m | \u001b[39m3.5479515\u001b[39m | \u001b[39m0.2480090\u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m0.8569356\u001b[39m | \u001b[39m52.530005\u001b[39m | \u001b[39m19.178344\u001b[39m | \u001b[39m8.2076700\u001b[39m | \u001b[39m1.2373480\u001b[39m | \u001b[39m0.5695024\u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m0.8577646\u001b[39m | \u001b[39m63.137940\u001b[39m | \u001b[39m30.0     \u001b[39m | \u001b[39m9.2379917\u001b[39m | \u001b[39m9.7695568\u001b[39m | \u001b[39m0.5605502\u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m0.8599611\u001b[39m | \u001b[39m107.95732\u001b[39m | \u001b[39m27.886305\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m1.4374019\u001b[39m | \u001b[39m0.5314927\u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m0.8525839\u001b[39m | \u001b[39m153.07206\u001b[39m | \u001b[39m9.5885736\u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.1600006\u001b[39m |\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m0.8575158\u001b[39m | \u001b[39m102.72633\u001b[39m | \u001b[39m19.815066\u001b[39m | \u001b[39m16.555514\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.1      \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m0.8581375\u001b[39m | \u001b[39m112.10517\u001b[39m | \u001b[39m29.059007\u001b[39m | \u001b[39m18.832401\u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m0.2177919\u001b[39m |\n",
      "=====================================================================================\n",
      "\n",
      "======================================================================\n",
      "BEST PARAMETERS FOUND\n",
      "======================================================================\n",
      "n_estimators: 143\n",
      "max_depth: 28\n",
      "min_samples_split: 15\n",
      "min_samples_leaf: 6\n",
      "max_features: 0.240\n",
      "\n",
      "======================================================================\n",
      "MODEL PERFORMANCE COMPARISON\n",
      "======================================================================\n",
      "Baseline Accuracy:        0.8543\n",
      "Best Cross-Val Accuracy:  0.8603\n",
      "Optimized Test Accuracy:  0.8613\n",
      "\n",
      "Improvement: 0.81%\n",
      "\n",
      "======================================================================\n",
      "TOP 5 TRIALS\n",
      "======================================================================\n",
      "\n",
      "Rank 1: Score = 0.8603\n",
      "  n_estimators: 143\n",
      "  max_depth: 28\n",
      "  min_samples_split: 15\n",
      "  min_samples_leaf: 6\n",
      "  max_features: 0.240\n",
      "\n",
      "Rank 2: Score = 0.8603\n",
      "  n_estimators: 54\n",
      "  max_depth: 29\n",
      "  min_samples_split: 3\n",
      "  min_samples_leaf: 3\n",
      "  max_features: 0.248\n",
      "\n",
      "Rank 3: Score = 0.8602\n",
      "  n_estimators: 103\n",
      "  max_depth: 24\n",
      "  min_samples_split: 12\n",
      "  min_samples_leaf: 8\n",
      "  max_features: 0.347\n",
      "\n",
      "Rank 4: Score = 0.8600\n",
      "  n_estimators: 148\n",
      "  max_depth: 19\n",
      "  min_samples_split: 7\n",
      "  min_samples_leaf: 5\n",
      "  max_features: 0.282\n",
      "\n",
      "Rank 5: Score = 0.8600\n",
      "  n_estimators: 144\n",
      "  max_depth: 28\n",
      "  min_samples_split: 14\n",
      "  min_samples_leaf: 6\n",
      "  max_features: 0.373\n",
      "\n",
      "======================================================================\n",
      "OPTIMIZATION STATISTICS\n",
      "======================================================================\n",
      "Total trials: 25\n",
      "Best score: 0.8603\n",
      "Mean score: 0.8574\n",
      "Standard deviation: 0.0034\n",
      "Improvement over first trial: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 3: Bayesian Optimization for Hyperparameter Tuning\n",
    "print(\"=\"*70)\n",
    "print(\"BAYESIAN OPTIMIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define the objective function to maximize\n",
    "def rf_cv_score(n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features):\n",
    "    \"\"\"\n",
    "    Function to optimize. Returns the cross-validation score.\n",
    "    Bayesian Optimization will try to maximize this function.\n",
    "    \"\"\"\n",
    "    # Convert continuous parameters to appropriate types\n",
    "    n_estimators = int(n_estimators)\n",
    "    max_depth = int(max_depth) if max_depth > 0 else None\n",
    "    min_samples_split = int(min_samples_split)\n",
    "    min_samples_leaf = int(min_samples_leaf)\n",
    "    max_features = min(max(0.1, max_features), 1.0)  # Keep between 0.1 and 1.0\n",
    "    \n",
    "    # Create and evaluate the model\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Use cross-validation to get a robust score\n",
    "    cv_scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    return cv_scores.mean()\n",
    "\n",
    "# Define the parameter bounds for Bayesian Optimization\n",
    "param_bounds = {\n",
    "    'n_estimators': (50, 300),          # Number of trees\n",
    "    'max_depth': (5, 30),                # Maximum depth (will convert to None if needed)\n",
    "    'min_samples_split': (2, 20),        # Minimum samples to split\n",
    "    'min_samples_leaf': (1, 10),         # Minimum samples at leaf\n",
    "    'max_features': (0.1, 1.0)           # Fraction of features to consider\n",
    "}\n",
    "\n",
    "# Initialize Bayesian Optimization\n",
    "optimizer = BayesianOptimization(\n",
    "    f=rf_cv_score,\n",
    "    pbounds=param_bounds,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Run the optimization\n",
    "n_iterations = 20  # Number of iterations (exploration + exploitation)\n",
    "print(f\"\\nRunning Bayesian Optimization for {n_iterations} iterations...\")\n",
    "print(\"(This uses smart sampling to find optimal parameters efficiently)\\n\")\n",
    "\n",
    "optimizer.maximize(\n",
    "    init_points=5,      # Number of random exploration steps\n",
    "    n_iter=n_iterations # Number of Bayesian optimization steps\n",
    ")\n",
    "\n",
    "# Step 4: Display Results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BEST PARAMETERS FOUND\")\n",
    "print(\"=\"*70)\n",
    "best_params = optimizer.max['params']\n",
    "print(f\"n_estimators: {int(best_params['n_estimators'])}\")\n",
    "print(f\"max_depth: {int(best_params['max_depth']) if best_params['max_depth'] > 0 else None}\")\n",
    "print(f\"min_samples_split: {int(best_params['min_samples_split'])}\")\n",
    "print(f\"min_samples_leaf: {int(best_params['min_samples_leaf'])}\")\n",
    "print(f\"max_features: {best_params['max_features']:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Baseline Accuracy:        {baseline_accuracy:.4f}\")\n",
    "print(f\"Best Cross-Val Accuracy:  {optimizer.max['target']:.4f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=int(best_params['n_estimators']),\n",
    "    max_depth=int(best_params['max_depth']) if best_params['max_depth'] > 0 else None,\n",
    "    min_samples_split=int(best_params['min_samples_split']),\n",
    "    min_samples_leaf=int(best_params['min_samples_leaf']),\n",
    "    max_features=best_params['max_features'],\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_optimized = best_rf.predict(X_test)\n",
    "optimized_accuracy = accuracy_score(y_test, y_pred_optimized)\n",
    "print(f\"Optimized Test Accuracy:  {optimized_accuracy:.4f}\")\n",
    "\n",
    "# Calculate improvement\n",
    "improvement = (optimized_accuracy - baseline_accuracy) / baseline_accuracy * 100\n",
    "print(f\"\\nImprovement: {improvement:.2f}%\")\n",
    "\n",
    "# Display top 5 trials\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TOP 5 TRIALS\")\n",
    "print(\"=\"*70)\n",
    "# Sort all results by target score\n",
    "all_results = []\n",
    "for i, res in enumerate(optimizer.res):\n",
    "    all_results.append({\n",
    "        'trial': i + 1,\n",
    "        'score': res['target'],\n",
    "        'params': res['params']\n",
    "    })\n",
    "\n",
    "# Sort by score and get top 5\n",
    "sorted_results = sorted(all_results, key=lambda x: x['score'], reverse=True)[:5]\n",
    "for rank, result in enumerate(sorted_results, 1):\n",
    "    print(f\"\\nRank {rank}: Score = {result['score']:.4f}\")\n",
    "    print(f\"  n_estimators: {int(result['params']['n_estimators'])}\")\n",
    "    print(f\"  max_depth: {int(result['params']['max_depth'])}\")\n",
    "    print(f\"  min_samples_split: {int(result['params']['min_samples_split'])}\")\n",
    "    print(f\"  min_samples_leaf: {int(result['params']['min_samples_leaf'])}\")\n",
    "    print(f\"  max_features: {result['params']['max_features']:.3f}\")\n",
    "\n",
    "# Additional statistics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OPTIMIZATION STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "all_scores = [res['target'] for res in optimizer.res]\n",
    "print(f\"Total trials: {len(optimizer.res)}\")\n",
    "print(f\"Best score: {max(all_scores):.4f}\")\n",
    "print(f\"Mean score: {np.mean(all_scores):.4f}\")\n",
    "print(f\"Standard deviation: {np.std(all_scores):.4f}\")\n",
    "print(f\"Improvement over first trial: {(max(all_scores) - all_scores[0]) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a0c74f",
   "metadata": {
    "part_id": "ex3-part5"
   },
   "source": [
    "#### Step 4: Compare and Reflect\n",
    "\n",
    "\n",
    "Compare the outputs of the different strategies.  Do they converge to similar parameters?  Why or why not?  Which method would you try first in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b8f333",
   "metadata": {
    "part_id": "ex3-part5",
    "span": "ex3-part5.answer",
    "student": true
   },
   "source": [
    "*Enter your answer in this cell*\n",
    "All three methods showed moderate convergence and achieved nearly identical performance (GridSearch: 0.8607, RandomSearch: 0.8603, Bayesian: 0.8603), but with notably different parameters - GridSearch used 100 estimators with min_samples_split=10, RandomSearch chose 207 estimators with bootstrap disabled, and Bayesian settled on 144-150 estimators with max_depth28-29. These differences exist because multiple parameter combinations achieve similar performance due to a flat optimization plateau near the optimum. In practice, start with RandomizedSearchCV - it matched the best performance (0.8618 test accuracy) while being simpler to implement, requiring no extra libraries, and exploring wider parameter spaces including categorical options. Bayesian optimization showed 0.00% improvement over its first trial, indicating this parameter space was too easy to benefit from sophisticated sequential learning. RandomizedSearchCV offers the best balance of simplicity, speed, and effectiveness for initial exploration, reserving Bayesian methods for expensive evaluations and GridSearch for final fine-tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
