# Assignment Feedback: Week 10: Ensemble Methods

**Student:** 0223josie
**Raw Score:** 23/23 (100.0%)
**Course Points Earned:** 4

---

## Problem Breakdown

### **Exercise 1** (10/10 = 100.0%)

**Part ex1-part2** (ex1-part2.code): 3/3 points

_Feedback:_ Good job. You implemented a BaggingClassifier with 10 decision trees and compared CV accuracy to a single tree, consistent with your prior work. The approach and evaluation are correct. Minor: you could use the estimator= keyword, but your code is fine.

**Part ex1-part3** (ex1-part3.code): 3/3 points

_Feedback:_ Good job: you trained Bagging with 10 estimators across max_samples 30/50/70/100% and compared performance (via CV), consistent with your prior work. Nice addition of Logistic Regression. For completeness, you could also report test-set accuracy, but full credit here.

**Part ex1-part4** (ex1-part4.code): 2/2 points

_Feedback:_ Correct implementation. You trained AdaBoost with 10 estimators and learning rate 1 using the prior synthetic dataset. Using decision stumps is appropriate. CV evaluation and comparisons to single tree and bagging are fine. No issues detected.

**Part ex1-part4** (ex1-part4.answer): 2/2 points

_Feedback:_ Correct: you trained AdaBoost with 10 estimators and learning_rate=1 on the same synthetic data and evaluated via CV. Using decision stumps as weak learners is appropriate. Extra comparisons to tree and bagging are fine. Full credit.

---

### **Exercise 2: Gradient Boosting for Regression** (5/5 = 100.0%)

**Part ex2-part1** (ex2-part1.code): 5/5 points

_Feedback:_ Well done. You used GradientBoostingRegressor with 50 estimators, a single train/test split, trained a DecisionTreeRegressor, computed and compared MSEs, and even added R² and improvement. Minor deviation: test_size=0.2 instead of 0.3, but acceptable. Full credit.

---

### **Exercise 3** (8/8 = 100.0%)

**Part ex3-part2** (ex3-part2.code): 3/3 points

_Feedback:_ Excellent: you used GridSearchCV with 36 combos (>=18), 5-fold CV, accuracy scoring, n_jobs=-1, and fit on prior X_train/y_train. You reported best params, CV score, test accuracy, and compared to baseline, plus top configs. Correct and thorough. Full credit.

**Part ex3-part3** (ex3-part3.code): 3/3 points

_Feedback:_ Well done: you used RandomizedSearchCV with appropriate parameter distributions and n_iter=25 (>=20), integrated with prior baseline, CV, and evaluation. Results and summary are clear. Minor: the separate `pip install` cell should use %pip/!pip or be omitted.

**Part ex3-part4** (ex3-part4.answer): 2/2 points

_Feedback:_ Excellent work. You correctly used bayesian-optimization, defined a proper objective with CV, explored >15 combos (init+iter), and trained/evaluated the final model. Clear reporting of best params, scores, and trial stats. Meets the task’s goals fully.

---

## Additional Information

This feedback was automatically generated by the autograder using LLM-based evaluation.

**Generated:** 2025-11-12 12:51:25 UTC

If you have questions about your grade, please reach out to the instructor.

---

*Powered by [Grade-Lite](https://github.com/your-repo/grade-lite) Autograder*