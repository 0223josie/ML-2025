{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Consider the following data:\n",
    "\n",
    "| Tid | Refund | Marital Status | Taxable Income (K) | Cheat |\n",
    "|-----|--------|----------------|--------------------|-------|\n",
    "| 1   | Yes    | Single         | 125                | No    |\n",
    "| 2   | No     | Married        | 100                | No    |\n",
    "| 3   | No     | Single         | 70                 | No    |\n",
    "| 4   | Yes    | Married        | 120                | No    |\n",
    "| 5   | No     | Divorced       | 95                 | Yes   |\n",
    "| 6   | No     | Married        | 60                 | No    |\n",
    "| 7   | Yes    | Divorced       | 220                | No    |\n",
    "| 8   | No     | Single         | 85                 | Yes   |\n",
    "| 9   | No     | Married        | 75                 | No    |\n",
    "| 10  | No     | Single         | 90                 | Yes   |\n",
    "\n",
    "Complete the code below to find the best split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Impurity for 'Refund' split: 0.3429\n",
      "Best Split: Column Marital Status with value Married gini score = 0.3\n",
      "Left group size: 4, Right group size: 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data provided\n",
    "data = {\n",
    "    'Tid': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'Refund': ['Yes', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No'],\n",
    "    'Marital Status': ['Single', 'Married', 'Single', 'Married', 'Divorced', 'Married', 'Divorced', 'Single', 'Married', 'Single'],\n",
    "    'Taxable Income (K)': [125, 100, 70, 120, 95, 60, 220, 85, 75, 90],\n",
    "    'Cheat': ['No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes']\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# @TODO Function to calculate Gini impurity\n",
    "def gini_impurity(groups, classes):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate the Gini impurity for a split.\n",
    "    \n",
    "    Parameters:\n",
    "    - groups: list of arrays/series, where each element contains the class labels for a group\n",
    "    - classes: list of unique class labels\n",
    "    \n",
    "    Returns:\n",
    "    - weighted Gini impurity for the split\n",
    "    \"\"\"\n",
    "    # Total number of instances\n",
    "    total_instances = sum(len(group) for group in groups)\n",
    "    \n",
    "    # Calculate weighted Gini impurity\n",
    "    gini = 0.0\n",
    "    \n",
    "    for group in groups:\n",
    "        size = len(group)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if size == 0:\n",
    "            continue\n",
    "        \n",
    "        # Calculate Gini impurity for this group\n",
    "        score = 0.0\n",
    "        for class_val in classes:\n",
    "            # Proportion of class_val in this group\n",
    "            proportion = list(group).count(class_val) / size\n",
    "            score += proportion ** 2\n",
    "        \n",
    "        # Gini impurity = 1 - sum(p^2)\n",
    "        group_gini = 1.0 - score\n",
    "        \n",
    "        # Weight the group's Gini by its relative size\n",
    "        gini += group_gini * (size / total_instances)\n",
    "    \n",
    "    return gini\n",
    "# Split by 'Refund' attribute\n",
    "refund_yes = df[df['Refund'] == 'Yes']['Cheat']\n",
    "refund_no = df[df['Refund'] == 'No']['Cheat']\n",
    "groups = [refund_yes, refund_no]\n",
    "classes = ['Yes', 'No']\n",
    "\n",
    "gini_score = gini_impurity(groups, classes)\n",
    "print(f\"Gini Impurity for 'Refund' split: {gini_score:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# @TODO Function to split a dataset based on a column and a value\n",
    "# Should return a tuple of left and right arrays\n",
    "# For numeric columns, left should be <= the value\n",
    "# For categorical columns, left should be == the value\n",
    "def test_split(column, value, df):\n",
    "    left, right = [], []\n",
    "    # Check if the column is numeric or categorical\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        # Numeric split: left <= value, right > value\n",
    "        left = df[df[column] <= value]\n",
    "        right = df[df[column] > value]\n",
    "    else:\n",
    "        # Categorical split: left == value, right != value\n",
    "        left = df[df[column] == value]\n",
    "        right = df[df[column] != value]\n",
    "    \n",
    "    return left, right\n",
    "\n",
    "# Function to get quartiles for continuous variables\n",
    "def get_quartiles(series):\n",
    "    return np.percentile(series, [25, 50, 75])\n",
    "\n",
    "# Function to find the best split\n",
    "def get_best_split(df_subset):\n",
    "    dataset = df_subset.values.tolist()  # Convert dataframe subset to list of lists\n",
    "    class_values = list(df_subset['Cheat'].unique())  # Unique class labels in this subset\n",
    "    best_column, best_value, best_gini, best_groups = None, None, float('inf'), None\n",
    "    \n",
    "    # Iterate over each column (feature)\n",
    "    for column in df_subset.columns[:-1]:  # Exclude the target variable 'Cheat'\n",
    "        if df_subset[column].dtype == 'object':  # Categorical column\n",
    "            unique_values = df_subset[column].unique()\n",
    "            for value in unique_values:\n",
    "                groups = test_split(df_subset.columns.get_loc(column), value, dataset)\n",
    "                if len(groups[0]) == 0 or len(groups[1]) == 0:\n",
    "                    continue\n",
    "                gini = gini_impurity(groups, class_values)\n",
    "                if gini < best_gini:\n",
    "                    best_column, best_value, best_gini, best_groups = column, value, gini, groups\n",
    "        \n",
    "        elif np.issubdtype(df_subset[column].dtype, np.number):  # Numeric column\n",
    "            # Use quartiles of the current subset\n",
    "            quartiles = get_quartiles(df_subset[column])\n",
    "            for value in quartiles:  # Try splitting by quartiles\n",
    "                groups = test_split(df_subset.columns.get_loc(column), value, dataset)\n",
    "                if len(groups[0]) == 0 or len(groups[1]) == 0:\n",
    "                    continue\n",
    "                gini = gini_impurity(groups, class_values)\n",
    "                if gini < best_gini:\n",
    "                    best_column, best_value, best_gini, best_groups = column, value, gini, groups\n",
    "    \n",
    "    return {'column': best_column, 'value': best_value, 'gini': best_gini, 'groups': best_groups}\n",
    "\n",
    "# Function to split a DataFrame based on a column and value\n",
    "def split_dataframe(df_subset, column, value):\n",
    "    \"\"\"Split a DataFrame into two based on a column and value\"\"\"\n",
    "    if isinstance(value, (int, float)):\n",
    "        left = df_subset[df_subset[column] <= value]\n",
    "        right = df_subset[df_subset[column] > value]\n",
    "    else:\n",
    "        left = df_subset[df_subset[column] == value]\n",
    "        right = df_subset[df_subset[column] != value]\n",
    "    return left, right\n",
    "\n",
    "# Function to find the best split\n",
    "def get_best_split(df, target_column='Cheat'):\n",
    "    \"\"\"\n",
    "    Find the best split for a DataFrame by trying all possible splits.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - target_column: the column containing class labels (default 'Cheat')\n",
    "    \n",
    "    Returns:\n",
    "    - dictionary with best split information\n",
    "    \"\"\"\n",
    "    best_gini = float('inf')\n",
    "    best_split = {}\n",
    "    # Get unique classes\n",
    "    classes = df[target_column].unique()\n",
    "    \n",
    "    # Try splitting on each column (except Tid and the target column)\n",
    "    for column in df.columns:\n",
    "        if column in ['Tid', target_column]:\n",
    "            continue\n",
    "        \n",
    "        # Get unique values in this column\n",
    "        unique_values = df[column].unique()\n",
    "        \n",
    "        # For numeric columns, try splitting at each unique value\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            for value in unique_values:\n",
    "                left, right = split_dataframe(df, column, value)\n",
    "                \n",
    "                # Skip if split results in empty groups\n",
    "                if len(left) == 0 or len(right) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate Gini impurity\n",
    "                groups = [left[target_column], right[target_column]]\n",
    "                gini = gini_impurity(groups, classes)\n",
    "                \n",
    "                # Update best split if this is better\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_split = {\n",
    "                        'column': column,\n",
    "                        'value': value,\n",
    "                        'gini': gini,\n",
    "                        'left_size': len(left),\n",
    "                        'right_size': len(right)\n",
    "                    }\n",
    "        \n",
    "        # For categorical columns, try each unique value\n",
    "        else:\n",
    "            for value in unique_values:\n",
    "                left, right = split_dataframe(df, column, value)\n",
    "                \n",
    "                # Skip if split results in empty groups\n",
    "                if len(left) == 0 or len(right) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate Gini impurity\n",
    "                groups = [left[target_column], right[target_column]]\n",
    "                gini = gini_impurity(groups, classes)\n",
    "                \n",
    "                # Update best split if this is better\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_split = {\n",
    "                        'column': column,\n",
    "                        'value': value,\n",
    "                        'gini': gini,\n",
    "                        'left_size': len(left),\n",
    "                        'right_size': len(right)\n",
    "                    }\n",
    "    \n",
    "    return best_split\n",
    "\n",
    "# Call the function to find the best split\n",
    "best_split = get_best_split(df)\n",
    "print('Best Split: Column', best_split['column'], 'with value', best_split['value'], 'gini score =', best_split['gini'])\n",
    "print(f\"Left group size: {best_split['left_size']}, Right group size: {best_split['right_size']}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brief Explanation of Results:\n",
    "1. Refund Split (Gini = 0.3429)\n",
    "\n",
    "Splitting by \"Refund\" creates moderately mixed groups\n",
    "Not the best feature for predicting who cheats\n",
    "\n",
    "2. Best Split: Marital Status = \"Married\" (Gini = 0.3000)\n",
    "\n",
    "This is the optimal first split for the decision tree\n",
    "Marital Status is better than Refund for separating cheaters from non-cheaters\n",
    "Lower Gini (0.30 vs 0.34) = better separation\n",
    "\n",
    "3. Group Sizes:\n",
    "\n",
    "Left group (Married): 4 people\n",
    "Right group (Not Married): 6 people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Try using the preceding code to implement a complete decision tree algorithm! You will need to use a list to keep track of where you are in the tree.\n",
    "\n",
    "**Hint 1: Think of it like a \"to-do list\"**\n",
    "\n",
    "- Start with your full dataset as your first \"task\"\n",
    "- When you split a dataset, you create two new \"tasks\" (left and right groups)\n",
    "- Keep these tasks in a list - what happens when you add new tasks to the end and always work on the last task? Try it with a simple example on paper first!\n",
    "\n",
    "**Hint 2: What information do you need to remember?**\n",
    "\n",
    "For each \"task\" in your list, you'll need to track:\n",
    "\n",
    "- The subset of data you're working with\n",
    "- How deep you are in the tree (start at depth 0)\n",
    "- The conditions that got you here (like \"Refund == 'Yes' AND Income <= 85\")\n",
    "\n",
    "**Hint 3: When do you stop splitting?**\n",
    "\n",
    "Think about when it doesn't make sense to split further:\n",
    "\n",
    "- When all samples in a group have the same class (all \"Cheat\" or all \"Don't Cheat\")\n",
    "- When you've gone too deep (set a maximum depth like 3)\n",
    "- When you have too few samples to split meaningfully\n",
    "\n",
    "**Hint 4: Process one group completely before moving to another**\n",
    "\n",
    "- Use .pop() to take the last item from your to-do list\n",
    "- This naturally makes you finish one \"branch\" before starting another\n",
    "- When you can't split anymore, print out the rule you've discovered!\n",
    "\n",
    "**Hint 5: Building the rule strings**\n",
    "\n",
    "- As you go deeper, add conditions to a list: [\"Refund == 'Yes'\", \"Income <= 85\"]\n",
    "- When you reach a leaf (can't split anymore), combine them: \"IF Refund == 'Yes' AND Income <= 85 THEN Cheat = 'No'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Level 0: 10 samples\n",
      "Class distribution: {'No': 7, 'Yes': 3}\n",
      "Split on 'Marital Status' with value 'Married' (Gini = 0.3000)\n",
      "\n",
      "  Level 1: 4 samples\n",
      "  Class distribution: {'No': 4}\n",
      "  → LEAF: Predict 'No'\n",
      "     Rule #1: IF Marital Status == 'Married' THEN Cheat = 'No'\n",
      "\n",
      "  Level 1: 6 samples\n",
      "  Class distribution: {'No': 3, 'Yes': 3}\n",
      "  Split on 'Refund' with value 'Yes' (Gini = 0.2500)\n",
      "\n",
      "    Level 2: 2 samples\n",
      "    Class distribution: {'No': 2}\n",
      "    → LEAF: Predict 'No'\n",
      "       Rule #2: IF Marital Status != 'Married' AND Refund == 'Yes' THEN Cheat = 'No'\n",
      "\n",
      "    Level 2: 4 samples\n",
      "    Class distribution: {'Yes': 3, 'No': 1}\n",
      "    Split on 'Taxable Income (K)' with value '70' (Gini = 0.0000)\n",
      "\n",
      "      Level 3: 1 samples\n",
      "      Class distribution: {'No': 1}\n",
      "      → LEAF: Predict 'No'\n",
      "         Rule #3: IF Marital Status != 'Married' AND Refund != 'Yes' AND Taxable Income (K) == '70' THEN Cheat = 'No'\n",
      "\n",
      "      Level 3: 3 samples\n",
      "      Class distribution: {'Yes': 3}\n",
      "      → LEAF: Predict 'Yes'\n",
      "         Rule #4: IF Marital Status != 'Married' AND Refund != 'Yes' AND Taxable Income (K) != '70' THEN Cheat = 'Yes'\n"
     ]
    }
   ],
   "source": [
    "# Simple depth-first tree builder using DataFrame subsetting\n",
    "def build_tree_dfs(df, max_depth=3, min_samples=2):\n",
    "    \"\"\"Build a decision tree using a simple stack-based DFS approach\"\"\"\n",
    "    \n",
    "    # Initialize stack with: (df_subset, depth, path_conditions)\n",
    "    stack = []\n",
    "    stack.append((df, 0, []))\n",
    "    \n",
    "    rule_number = 1\n",
    "    \n",
    "    while stack:\n",
    "        df_subset, depth, conditions = stack.pop()\n",
    "        \n",
    "        # Get class distribution\n",
    "        class_counts = df_subset['Cheat'].value_counts().to_dict()\n",
    "        unique_classes = list(class_counts.keys())\n",
    "        \n",
    "        print(f\"\\n{'  ' * depth}Level {depth}: {len(df_subset)} samples\")\n",
    "        print(f\"{'  ' * depth}Class distribution: {class_counts}\")\n",
    "\n",
    "    # THE REST IS UP TO YOU!\n",
    "# Check stopping conditions\n",
    "        # 1. Pure node (only one class)\n",
    "        if len(unique_classes) == 1:\n",
    "            print(f\"{'  ' * depth}→ LEAF: Predict '{unique_classes[0]}'\")\n",
    "            print(f\"{'  ' * depth}   Rule #{rule_number}: IF {' AND '.join(conditions) if conditions else 'root'} THEN Cheat = '{unique_classes[0]}'\")\n",
    "            rule_number += 1\n",
    "            continue\n",
    "        \n",
    "        # 2. Max depth reached\n",
    "        if depth >= max_depth:\n",
    "            majority_class = max(class_counts, key=class_counts.get)\n",
    "            print(f\"{'  ' * depth}→ LEAF (max depth): Predict '{majority_class}'\")\n",
    "            print(f\"{'  ' * depth}   Rule #{rule_number}: IF {' AND '.join(conditions) if conditions else 'root'} THEN Cheat = '{majority_class}'\")\n",
    "            rule_number += 1\n",
    "            continue\n",
    "        \n",
    "        # 3. Too few samples\n",
    "        if len(df_subset) < min_samples:\n",
    "            majority_class = max(class_counts, key=class_counts.get)\n",
    "            print(f\"{'  ' * depth}→ LEAF (min samples): Predict '{majority_class}'\")\n",
    "            print(f\"{'  ' * depth}   Rule #{rule_number}: IF {' AND '.join(conditions) if conditions else 'root'} THEN Cheat = '{majority_class}'\")\n",
    "            rule_number += 1\n",
    "            continue\n",
    "        \n",
    "        # Find the best split for this subset\n",
    "        best_split = get_best_split(df_subset)\n",
    "        \n",
    "        # 4. No valid split found\n",
    "        if not best_split:\n",
    "            majority_class = max(class_counts, key=class_counts.get)\n",
    "            print(f\"{'  ' * depth}→ LEAF (no split): Predict '{majority_class}'\")\n",
    "            print(f\"{'  ' * depth}   Rule #{rule_number}: IF {' AND '.join(conditions) if conditions else 'root'} THEN Cheat = '{majority_class}'\")\n",
    "            rule_number += 1\n",
    "            continue\n",
    "        \n",
    "        # Display the split\n",
    "        print(f\"{'  ' * depth}Split on '{best_split['column']}' with value '{best_split['value']}' (Gini = {best_split['gini']:.4f})\")\n",
    "        \n",
    "        # Split the data\n",
    "        left, right = split_dataframe(df_subset, best_split['column'], best_split['value'])\n",
    "        \n",
    "        # Create condition strings\n",
    "        if isinstance(best_split['value'], (int, float)):\n",
    "            left_condition = f\"{best_split['column']} <= {best_split['value']}\"\n",
    "            right_condition = f\"{best_split['column']} > {best_split['value']}\"\n",
    "        else:\n",
    "            left_condition = f\"{best_split['column']} == '{best_split['value']}'\"\n",
    "            right_condition = f\"{best_split['column']} != '{best_split['value']}'\"\n",
    "        \n",
    "        # Push right child first (so left is processed first - DFS left-to-right)\n",
    "        if len(right) > 0:\n",
    "            right_conditions = conditions + [right_condition]\n",
    "            stack.append((right, depth + 1, right_conditions))\n",
    "        \n",
    "        if len(left) > 0:\n",
    "            left_conditions = conditions + [left_condition]\n",
    "            stack.append((left, depth + 1, left_conditions))\n",
    "\n",
    "build_tree_dfs(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Build a decision tree to fit the [federalist papers](https://www.kaggle.com/datasets/tobyanderson/federalist-papers_) data, available in the data directory (click on the link to find out more information about this data). Note that you should restrict your analysis to papers by Hamilton or Madison.  Plot your training and test scores to pick a value for ccp_alpha. What did you pick?  Run your trained classifier on the \"disputed\" papers.  What does your model tell you? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
